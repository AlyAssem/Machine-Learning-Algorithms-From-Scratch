{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(len_weights_vector):\n",
    "    \"\"\"Initializes the weights of all the features and the bias to 0.\"\"\"\n",
    "    weights = np.zeros((1, len_weights_vector)) # 1 row vector of weights. \n",
    "    bias = 0\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, W, b):  #W-->1xn, X-->nxm n=#features, m=#training samples.\n",
    "    \"\"\"Returns the predictions vector.\"\"\"\n",
    "    y_predictions = np.dot(W, X) + b  #y_predictions--> 1xm B = [b b b]--> 1xm\n",
    "    return y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(y_predictions, y):# z->1xm, y->1xm\n",
    "    \"\"\"returns the error between the predictions and the actual values.\"\"\"\n",
    "    \n",
    "    m = y.shape[1] # number of training samples.\n",
    "    # Mean squared error.\n",
    "    j = (1/(2 * m)) * np.sum(np.square(y_predictions - y))\n",
    "    return j   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(X, y, y_predictions): #x-->nxm, y->1xm, y_predictions->1xm\n",
    "    \"\"\"Returns the partial derivatives for the weights and bias.\"\"\"\n",
    "    m = y.shape[1] # number of training samples.\n",
    "    # rate of change of cost function with respect to the predictions vector.\n",
    "    d_yhat = (1 / m) * (y_predictions - y)  #dz -> 1xm\n",
    "    # rate of change of cost function with respect to the weights vector.\n",
    "    dw = np.dot(d_yhat, X.T) #dw ->1xn.\n",
    "    # rate of change of cost function with respect to the bias vector.\n",
    "    db = np.sum(d_yhat)  #db -> 1xm.\n",
    "    \n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_update(w, b, dw, db, learning_rate): #learning rate is a constant.\n",
    "    \"\"\"Returns the updated values for the weights and bias.\"\"\"\n",
    "    w = w - learning_rate * dw\n",
    "    b = b - learning_rate * db\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_model(X_train, y_train, X_test, y_test, learning_rate, epochs):#epochs is how many iterations through the training data.\n",
    "    \n",
    "    len_weights_vector = X_train.shape[0] # number of rows(features).\n",
    "    w, b = init_parameters(len_weights_vector)\n",
    "    \n",
    "    costs_train = []\n",
    "    m_train = y_train.shape[1] # number of training samples.\n",
    "    m_test = y_test.shape[1] # number of test samples.\n",
    "    \n",
    "    for i in range(1, epochs + 1):# epochs + 1 cuz we are starting from 1 not 0\n",
    "        # predictions for the train dataset.\n",
    "        y_predictions_train = forward_prop(X_train, w, b)\n",
    "        # computation of cost function for the training dataset.\n",
    "        cost_train = cost_function(y_predictions_train, y_train)\n",
    "        # compute the rates of changes of the cost function with respect to the weights and bias.\n",
    "        dw, db = back_prop(X_train, y_train, y_predictions_train)\n",
    "        # re-assign values to the weights and bias to minimize the error.\n",
    "        w, b = gradient_descent_update(w, b, dw, db, learning_rate)\n",
    "        \n",
    "        # store all training costs in a list for plotting.\n",
    "        if i % 10 ==0: # for every 10 iterations.\n",
    "            costs_train.append(cost_train)\n",
    "        \n",
    "        # Mean absolute error for the training dataset.\n",
    "        MAE_train = (1 / m_train) * np.sum(np.abs(y_predictions_train - y_train))\n",
    "        \n",
    "        # cost function, MAE for the test set.\n",
    "        y_predictions_test = forward_prop(X_test, w, b)\n",
    "        cost_test = cost_function(y_predictions_test, y_test)\n",
    "        MAE_test = (1 / m_test) * np.sum(np.abs(y_predictions_test - y_test))\n",
    "        \n",
    "        # print the cost_train, cost_test, MAE_train, MAE_test\n",
    "        print('Epochs' + str(i) + '/' + str(epochs) + ': ')\n",
    "        print('Training cost ' + str(cost_train) + '|' + \"test cost \" + str(cost_test))\n",
    "        print('Training MAE ' + str(MAE_train) + '|' + \"test MAE \" + str(MAE_test))\n",
    "        \n",
    "        \n",
    "    # plotting the training costs per 10 iterations to check if the error is decreasing or not.\n",
    "    plt.plot(costs_train)\n",
    "    plt.xlabel('Iterations per tens')\n",
    "    plt.ylabel('Training cost')\n",
    "    plt.title('Learning rate ' + str(learning_rate))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's time to test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'c:\\\\users\\\\aly\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boston is a dictionary containing key value pairs(e.g. data, target, feature_names).\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 13 features for our dataset.\n",
    "boston['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 506 data samples and 13 features in our dataset.\n",
    "boston['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the data with their 13 features into a dataframe.\n",
    "df = pd.DataFrame(boston['data'], columns = boston['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null float64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null float64\n",
      "TAX        506 non-null float64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "# we have no missing data in our dataset.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our target value. that we would like to predict\n",
    "boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the input matrix so the data ranges between -1 to +1 with a mean of 0\n",
    "# for gradient descent to work faster.\n",
    "# Mean normalization.\n",
    "X = (df - df.mean()) / (df.max() - df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-7.021173e-18</td>\n",
       "      <td>7.898820e-18</td>\n",
       "      <td>-7.828608e-16</td>\n",
       "      <td>-1.579764e-17</td>\n",
       "      <td>6.389268e-16</td>\n",
       "      <td>-1.544219e-15</td>\n",
       "      <td>-3.405269e-16</td>\n",
       "      <td>1.404235e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.808469e-17</td>\n",
       "      <td>-2.341561e-15</td>\n",
       "      <td>1.976460e-15</td>\n",
       "      <td>-1.088282e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.667929e-02</td>\n",
       "      <td>2.332245e-01</td>\n",
       "      <td>2.514792e-01</td>\n",
       "      <td>2.539940e-01</td>\n",
       "      <td>2.384314e-01</td>\n",
       "      <td>1.346268e-01</td>\n",
       "      <td>2.898956e-01</td>\n",
       "      <td>1.914822e-01</td>\n",
       "      <td>0.378576</td>\n",
       "      <td>3.216357e-01</td>\n",
       "      <td>2.303134e-01</td>\n",
       "      <td>2.302054e-01</td>\n",
       "      <td>1.970492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.054410e-02</td>\n",
       "      <td>-1.136364e-01</td>\n",
       "      <td>-3.913775e-01</td>\n",
       "      <td>-6.916996e-02</td>\n",
       "      <td>-3.491668e-01</td>\n",
       "      <td>-5.218690e-01</td>\n",
       "      <td>-6.763636e-01</td>\n",
       "      <td>-2.423813e-01</td>\n",
       "      <td>-0.371713</td>\n",
       "      <td>-4.222083e-01</td>\n",
       "      <td>-6.229291e-01</td>\n",
       "      <td>-8.985678e-01</td>\n",
       "      <td>-3.014090e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.969297e-02</td>\n",
       "      <td>-1.136364e-01</td>\n",
       "      <td>-2.179904e-01</td>\n",
       "      <td>-6.916996e-02</td>\n",
       "      <td>-2.174795e-01</td>\n",
       "      <td>-7.647718e-02</td>\n",
       "      <td>-2.425325e-01</td>\n",
       "      <td>-1.541223e-01</td>\n",
       "      <td>-0.241279</td>\n",
       "      <td>-2.466358e-01</td>\n",
       "      <td>-1.122908e-01</td>\n",
       "      <td>4.716191e-02</td>\n",
       "      <td>-1.573693e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.773202e-02</td>\n",
       "      <td>-1.136364e-01</td>\n",
       "      <td>-5.303441e-02</td>\n",
       "      <td>-6.916996e-02</td>\n",
       "      <td>-3.435197e-02</td>\n",
       "      <td>-1.458793e-02</td>\n",
       "      <td>9.191657e-02</td>\n",
       "      <td>-5.343258e-02</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>-1.493075e-01</td>\n",
       "      <td>6.324111e-02</td>\n",
       "      <td>8.766445e-02</td>\n",
       "      <td>-3.568055e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.143872e-04</td>\n",
       "      <td>1.136364e-02</td>\n",
       "      <td>2.552500e-01</td>\n",
       "      <td>-6.916996e-02</td>\n",
       "      <td>1.426028e-01</td>\n",
       "      <td>6.492922e-02</td>\n",
       "      <td>2.626169e-01</td>\n",
       "      <td>1.267068e-01</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>4.919138e-01</td>\n",
       "      <td>1.855815e-01</td>\n",
       "      <td>9.973011e-02</td>\n",
       "      <td>1.187069e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.594559e-01</td>\n",
       "      <td>8.863636e-01</td>\n",
       "      <td>6.086225e-01</td>\n",
       "      <td>9.308300e-01</td>\n",
       "      <td>6.508332e-01</td>\n",
       "      <td>4.781310e-01</td>\n",
       "      <td>3.236364e-01</td>\n",
       "      <td>7.576187e-01</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>5.777917e-01</td>\n",
       "      <td>3.770709e-01</td>\n",
       "      <td>1.014322e-01</td>\n",
       "      <td>6.985910e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CRIM            ZN         INDUS          CHAS           NOX  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean  -7.021173e-18  7.898820e-18 -7.828608e-16 -1.579764e-17  6.389268e-16   \n",
       "std    9.667929e-02  2.332245e-01  2.514792e-01  2.539940e-01  2.384314e-01   \n",
       "min   -4.054410e-02 -1.136364e-01 -3.913775e-01 -6.916996e-02 -3.491668e-01   \n",
       "25%   -3.969297e-02 -1.136364e-01 -2.179904e-01 -6.916996e-02 -2.174795e-01   \n",
       "50%   -3.773202e-02 -1.136364e-01 -5.303441e-02 -6.916996e-02 -3.435197e-02   \n",
       "75%    7.143872e-04  1.136364e-02  2.552500e-01 -6.916996e-02  1.426028e-01   \n",
       "max    9.594559e-01  8.863636e-01  6.086225e-01  9.308300e-01  6.508332e-01   \n",
       "\n",
       "                 RM           AGE           DIS         RAD           TAX  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  506.000000  5.060000e+02   \n",
       "mean  -1.544219e-15 -3.405269e-16  1.404235e-16    0.000000  2.808469e-17   \n",
       "std    1.346268e-01  2.898956e-01  1.914822e-01    0.378576  3.216357e-01   \n",
       "min   -5.218690e-01 -6.763636e-01 -2.423813e-01   -0.371713 -4.222083e-01   \n",
       "25%   -7.647718e-02 -2.425325e-01 -1.541223e-01   -0.241279 -2.466358e-01   \n",
       "50%   -1.458793e-02  9.191657e-02 -5.343258e-02   -0.197800 -1.493075e-01   \n",
       "75%    6.492922e-02  2.626169e-01  1.267068e-01    0.628287  4.919138e-01   \n",
       "max    4.781310e-01  3.236364e-01  7.576187e-01    0.628287  5.777917e-01   \n",
       "\n",
       "            PTRATIO             B         LSTAT  \n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  \n",
       "mean  -2.341561e-15  1.976460e-15 -1.088282e-16  \n",
       "std    2.303134e-01  2.302054e-01  1.970492e-01  \n",
       "min   -6.229291e-01 -8.985678e-01 -3.014090e-01  \n",
       "25%   -1.122908e-01  4.716191e-02 -1.573693e-01  \n",
       "50%    6.324111e-02  8.766445e-02 -3.568055e-02  \n",
       "75%    1.855815e-01  9.973011e-02  1.187069e-01  \n",
       "max    3.770709e-01  1.014322e-01  6.985910e-01  "
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.040544</td>\n",
       "      <td>0.066364</td>\n",
       "      <td>-0.323562</td>\n",
       "      <td>-0.06917</td>\n",
       "      <td>-0.034352</td>\n",
       "      <td>0.055636</td>\n",
       "      <td>-0.034757</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>-0.371713</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>-0.335695</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.211729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.149075</td>\n",
       "      <td>-0.06917</td>\n",
       "      <td>-0.176327</td>\n",
       "      <td>0.026129</td>\n",
       "      <td>0.106335</td>\n",
       "      <td>0.106581</td>\n",
       "      <td>-0.328235</td>\n",
       "      <td>-0.317246</td>\n",
       "      <td>-0.069738</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.096939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.149075</td>\n",
       "      <td>-0.06917</td>\n",
       "      <td>-0.176327</td>\n",
       "      <td>0.172517</td>\n",
       "      <td>-0.076981</td>\n",
       "      <td>0.106581</td>\n",
       "      <td>-0.328235</td>\n",
       "      <td>-0.317246</td>\n",
       "      <td>-0.069738</td>\n",
       "      <td>0.091169</td>\n",
       "      <td>-0.237943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040251</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.328328</td>\n",
       "      <td>-0.06917</td>\n",
       "      <td>-0.198961</td>\n",
       "      <td>0.136686</td>\n",
       "      <td>-0.234551</td>\n",
       "      <td>0.206163</td>\n",
       "      <td>-0.284757</td>\n",
       "      <td>-0.355414</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.095708</td>\n",
       "      <td>-0.268021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.039839</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.328328</td>\n",
       "      <td>-0.06917</td>\n",
       "      <td>-0.198961</td>\n",
       "      <td>0.165236</td>\n",
       "      <td>-0.148042</td>\n",
       "      <td>0.206163</td>\n",
       "      <td>-0.284757</td>\n",
       "      <td>-0.355414</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.202071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS     CHAS       NOX        RM       AGE  \\\n",
       "0 -0.040544  0.066364 -0.323562 -0.06917 -0.034352  0.055636 -0.034757   \n",
       "1 -0.040308 -0.113636 -0.149075 -0.06917 -0.176327  0.026129  0.106335   \n",
       "2 -0.040308 -0.113636 -0.149075 -0.06917 -0.176327  0.172517 -0.076981   \n",
       "3 -0.040251 -0.113636 -0.328328 -0.06917 -0.198961  0.136686 -0.234551   \n",
       "4 -0.039839 -0.113636 -0.328328 -0.06917 -0.198961  0.165236 -0.148042   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.026822 -0.371713 -0.214193 -0.335695  0.101432 -0.211729  \n",
       "1  0.106581 -0.328235 -0.317246 -0.069738  0.101432 -0.096939  \n",
       "2  0.106581 -0.328235 -0.317246 -0.069738  0.091169 -0.237943  \n",
       "3  0.206163 -0.284757 -0.355414  0.026007  0.095708 -0.268021  \n",
       "4  0.206163 -0.284757 -0.355414  0.026007  0.101432 -0.202071  "
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our target variable we would like to predict.\n",
    "y = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 506 targets.\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 13)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 339 data samples out of the 506.\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 339)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the manually written model above requires the X_training of dimension\n",
    "# (number_features x number_training_examples)\n",
    "# transpose of X_train\n",
    "X_train = X_train.T\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339,)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 339)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the manually written model above requries the y_train of dimension\n",
    "# (1xm_train where m_train = number of training data.)\n",
    "y_train = np.array([y_train])\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 167)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarly for the test set.\n",
    "X_test = X_test.T\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 167)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.array([y_test])\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs1/500: \n",
      "Training cost 293.87502949852507|test cost 134.03952819592888\n",
      "Training MAE 22.53716814159292|test MAE 13.558080443847112\n",
      "Epochs2/500: \n",
      "Training cost 126.29007943286858|test cost 72.53024841900947\n",
      "Training MAE 13.556920515044165|test MAE 8.567173211994337\n",
      "Epochs3/500: \n",
      "Training cost 64.48605249549566|test cost 49.185779370784566\n",
      "Training MAE 8.584464564354887|test MAE 6.31150796331822\n",
      "Epochs4/500: \n",
      "Training cost 41.11837291662819|test cost 39.862788313569226\n",
      "Training MAE 6.132581495701579|test MAE 5.546871762049199\n",
      "Epochs5/500: \n",
      "Training cost 31.8464749408043|test cost 35.793142957204076\n",
      "Training MAE 5.146516386528717|test MAE 5.286502193398581\n",
      "Epochs6/500: \n",
      "Training cost 27.83511268481864|test cost 33.76085227950457\n",
      "Training MAE 4.895580497212939|test MAE 5.277031480869301\n",
      "Epochs7/500: \n",
      "Training cost 25.850905902447806|test cost 32.564577727950024\n",
      "Training MAE 4.834550492911536|test MAE 5.297071354069098\n",
      "Epochs8/500: \n",
      "Training cost 24.69226634260085|test cost 31.740922148360987\n",
      "Training MAE 4.818727390003807|test MAE 5.287123464972672\n",
      "Epochs9/500: \n",
      "Training cost 23.900044516819722|test cost 31.10156845661018\n",
      "Training MAE 4.801127010109081|test MAE 5.261340254897292\n",
      "Epochs10/500: \n",
      "Training cost 23.29020794837086|test cost 30.56397533796502\n",
      "Training MAE 4.773392311598197|test MAE 5.22470094039234\n",
      "Epochs11/500: \n",
      "Training cost 22.783303115359796|test cost 30.088403777147295\n",
      "Training MAE 4.740503207977458|test MAE 5.182517229858473\n",
      "Epochs12/500: \n",
      "Training cost 22.341417494427|test cost 29.653781289547904\n",
      "Training MAE 4.706422924903716|test MAE 5.138842260102843\n",
      "Epochs13/500: \n",
      "Training cost 21.94432392176347|test cost 29.24797919138913\n",
      "Training MAE 4.669573975528632|test MAE 5.097961043063666\n",
      "Epochs14/500: \n",
      "Training cost 21.58007574260132|test cost 28.86359464712298\n",
      "Training MAE 4.631487208653908|test MAE 5.057517703687145\n",
      "Epochs15/500: \n",
      "Training cost 21.241048397412673|test cost 28.49593916378584\n",
      "Training MAE 4.592772761185863|test MAE 5.0166386339624065\n",
      "Epochs16/500: \n",
      "Training cost 20.922113427000188|test cost 28.14197830761\n",
      "Training MAE 4.553886306288237|test MAE 4.976501377886081\n",
      "Epochs17/500: \n",
      "Training cost 20.619700541697586|test cost 27.799722153615615\n",
      "Training MAE 4.515365444533178|test MAE 4.937667776959757\n",
      "Epochs18/500: \n",
      "Training cost 20.33126368384957|test cost 27.46785217865199\n",
      "Training MAE 4.477474256309675|test MAE 4.89922891111391\n",
      "Epochs19/500: \n",
      "Training cost 20.054951496619907|test cost 27.14548382109058\n",
      "Training MAE 4.440320949400864|test MAE 4.861291988419947\n",
      "Epochs20/500: \n",
      "Training cost 19.78939261769668|test cost 26.832012189246\n",
      "Training MAE 4.40396704491347|test MAE 4.823911250698945\n",
      "Epochs21/500: \n",
      "Training cost 19.53355114444105|test cost 26.5270109130368\n",
      "Training MAE 4.368575409751747|test MAE 4.7871102358575195\n",
      "Epochs22/500: \n",
      "Training cost 19.2866275209565|test cost 26.230165776858797\n",
      "Training MAE 4.333982554637168|test MAE 4.753942391079861\n",
      "Epochs23/500: \n",
      "Training cost 19.047989872604553|test cost 25.941231386397128\n",
      "Training MAE 4.300543302908963|test MAE 4.721908356687506\n",
      "Epochs24/500: \n",
      "Training cost 18.817126157493732|test cost 25.660003156719622\n",
      "Training MAE 4.268131332027649|test MAE 4.690373897254401\n",
      "Epochs25/500: \n",
      "Training cost 18.593610704253862|test cost 25.386299487161615\n",
      "Training MAE 4.236977890980834|test MAE 4.659329756153543\n",
      "Epochs26/500: \n",
      "Training cost 18.3770807493008|test cost 25.119950682141276\n",
      "Training MAE 4.207482980619795|test MAE 4.629408527974564\n",
      "Epochs27/500: \n",
      "Training cost 18.167219946106556|test cost 24.860792306820514\n",
      "Training MAE 4.178560451908688|test MAE 4.600551997312079\n",
      "Epochs28/500: \n",
      "Training cost 17.963746744174408|test cost 24.608661426277287\n",
      "Training MAE 4.151172538757698|test MAE 4.572619556186342\n",
      "Epochs29/500: \n",
      "Training cost 17.76640617313009|test cost 24.363394689750734\n",
      "Training MAE 4.1246866124119945|test MAE 4.5450971759823675\n",
      "Epochs30/500: \n",
      "Training cost 17.57496400986011|test cost 24.124827568232554\n",
      "Training MAE 4.099229337948248|test MAE 4.517976583330385\n",
      "Epochs31/500: \n",
      "Training cost 17.389202614782548|test cost 23.892794287969853\n",
      "Training MAE 4.074337384113498|test MAE 4.4912497698343365\n",
      "Epochs32/500: \n",
      "Training cost 17.208917938315338|test cost 23.66712816049204\n",
      "Training MAE 4.050393185780331|test MAE 4.465153537366419\n",
      "Epochs33/500: \n",
      "Training cost 17.03391734872807|test cost 23.447662116060563\n",
      "Training MAE 4.026997785371193|test MAE 4.4399409320228544\n",
      "Epochs34/500: \n",
      "Training cost 16.86401803744613|test cost 23.23422931858285\n",
      "Training MAE 4.004894168293925|test MAE 4.415082596343294\n",
      "Epochs35/500: \n",
      "Training cost 16.699045831172768|test cost 23.02666378733741\n",
      "Training MAE 3.9833410882015627|test MAE 4.390572608364314\n",
      "Epochs36/500: \n",
      "Training cost 16.538834291426525|test cost 22.82480098202034\n",
      "Training MAE 3.9622380360709615|test MAE 4.36747495420744\n",
      "Epochs37/500: \n",
      "Training cost 16.383224017904034|test cost 22.628478327890182\n",
      "Training MAE 3.9416966346580398|test MAE 4.345086457725476\n",
      "Epochs38/500: \n",
      "Training cost 16.232062097115577|test cost 22.43753567072788\n",
      "Training MAE 3.9214621314385285|test MAE 4.323433680846334\n",
      "Epochs39/500: \n",
      "Training cost 16.085201655245726|test cost 22.25181565937124\n",
      "Training MAE 3.9017532726236777|test MAE 4.302626751378931\n",
      "Epochs40/500: \n",
      "Training cost 15.942501486432628|test cost 22.071164058381274\n",
      "Training MAE 3.8825637798658748|test MAE 4.282457153855178\n",
      "Epochs41/500: \n",
      "Training cost 15.80382573622032|test cost 21.895429996067463\n",
      "Training MAE 3.864118809442771|test MAE 4.262982315903569\n",
      "Epochs42/500: \n",
      "Training cost 15.669043625927403|test cost 21.72446615439736\n",
      "Training MAE 3.846251224790561|test MAE 4.244651273296327\n",
      "Epochs43/500: \n",
      "Training cost 15.538029207865794|test cost 21.558128907748742\n",
      "Training MAE 3.828988622285234|test MAE 4.227115767561468\n",
      "Epochs44/500: \n",
      "Training cost 15.410661144277126|test cost 21.396278417368794\n",
      "Training MAE 3.8125095466259755|test MAE 4.209996264846306\n",
      "Epochs45/500: \n",
      "Training cost 15.286822504908795|test cost 21.238778688006573\n",
      "Training MAE 3.7966729725393873|test MAE 4.193117702516643\n",
      "Epochs46/500: \n",
      "Training cost 15.166400579592036|test cost 21.085497592628798\n",
      "Training MAE 3.781299363627075|test MAE 4.176869383397861\n",
      "Epochs47/500: \n",
      "Training cost 15.049286703195007|test cost 20.93630687050607\n",
      "Training MAE 3.7663415726214318|test MAE 4.1614899674471495\n",
      "Epochs48/500: \n",
      "Training cost 14.935376091033763|test cost 20.7910821033259\n",
      "Training MAE 3.7516428759805023|test MAE 4.146610895284143\n",
      "Epochs49/500: \n",
      "Training cost 14.824567683324032|test cost 20.64970267338338\n",
      "Training MAE 3.73746719947368|test MAE 4.1321968375832565\n",
      "Epochs50/500: \n",
      "Training cost 14.716763997609323|test cost 20.512051707339808\n",
      "Training MAE 3.723636787421671|test MAE 4.117971151077291\n",
      "Epochs51/500: \n",
      "Training cost 14.611870988350814|test cost 20.37801600853191\n",
      "Training MAE 3.7100226472278224|test MAE 4.103930716413299\n",
      "Epochs52/500: \n",
      "Training cost 14.50979791304208|test cost 20.247485980363464\n",
      "Training MAE 3.6971845784863633|test MAE 4.090651725358101\n",
      "Epochs53/500: \n",
      "Training cost 14.410457204338877|test cost 20.120355542914485\n",
      "Training MAE 3.6846653757107926|test MAE 4.077884926316126\n",
      "Epochs54/500: \n",
      "Training cost 14.313764347786023|test cost 19.996522044558773\n",
      "Training MAE 3.6729885135697176|test MAE 4.065972594223737\n",
      "Epochs55/500: \n",
      "Training cost 14.219637764789999|test cost 19.87588617008339\n",
      "Training MAE 3.661594541106653|test MAE 4.055056069830424\n",
      "Epochs56/500: \n",
      "Training cost 14.12799870053532|test cost 19.758351846548614\n",
      "Training MAE 3.6505285232707476|test MAE 4.044304900358477\n",
      "Epochs57/500: \n",
      "Training cost 14.038771116579566|test cost 19.643826147909486\n",
      "Training MAE 3.6397864002417397|test MAE 4.033762778617167\n",
      "Epochs58/500: \n",
      "Training cost 13.951881587890059|test cost 19.532219199235772\n",
      "Training MAE 3.629184787265774|test MAE 4.0236625782526225\n",
      "Epochs59/500: \n",
      "Training cost 13.867259204107153|test cost 19.423444081210675\n",
      "Training MAE 3.6187354218908974|test MAE 4.0139624229079445\n",
      "Epochs60/500: \n",
      "Training cost 13.784835474836534|test cost 19.31741673545736\n",
      "Training MAE 3.6084665839881644|test MAE 4.004494887146863\n",
      "Epochs61/500: \n",
      "Training cost 13.704544238787166|test cost 19.214055871131674\n",
      "Training MAE 3.598329151768221|test MAE 3.995134916989884\n",
      "Epochs62/500: \n",
      "Training cost 13.626321576583516|test cost 19.113282873126956\n",
      "Training MAE 3.5883211383005946|test MAE 3.985880979717032\n",
      "Epochs63/500: \n",
      "Training cost 13.550105727090846|test cost 19.01502171215958\n",
      "Training MAE 3.5785572949201097|test MAE 3.9767315684763753\n",
      "Epochs64/500: \n",
      "Training cost 13.475837007101301|test cost 18.91919885693954\n",
      "Training MAE 3.5691049773985366|test MAE 3.9676852018904256\n",
      "Epochs65/500: \n",
      "Training cost 13.403457734236488|test cost 18.825743188577093\n",
      "Training MAE 3.5597736000413156|test MAE 3.958740423650436\n",
      "Epochs66/500: \n",
      "Training cost 13.332912152929453|test cost 18.734585917332378\n",
      "Training MAE 3.55066428846342|test MAE 3.9501357346888706\n",
      "Epochs67/500: \n",
      "Training cost 13.264146363355533|test cost 18.64566050177875\n",
      "Training MAE 3.541720227553878|test MAE 3.941687786455848\n",
      "Epochs68/500: \n",
      "Training cost 13.197108253187643|test cost 18.558902570420724\n",
      "Training MAE 3.5331206729374034|test MAE 3.9333283254047453\n",
      "Epochs69/500: \n",
      "Training cost 13.131747432057374|test cost 18.474249845783245\n",
      "Training MAE 3.524666296984407|test MAE 3.9250562082698224\n",
      "Epochs70/500: \n",
      "Training cost 13.068015168608385|test cost 18.391642070969393\n",
      "Training MAE 3.5163196035345488|test MAE 3.9168703094764004\n",
      "Epochs71/500: \n",
      "Training cost 13.00586433003401|test cost 18.311020938667916\n",
      "Training MAE 3.5080789436400646|test MAE 3.9093754746455343\n",
      "Epochs72/500: \n",
      "Training cost 12.945249323995276|test cost 18.23233002257931\n",
      "Training MAE 3.4999426970436534|test MAE 3.902179365561162\n",
      "Epochs73/500: \n",
      "Training cost 12.886126042820536|test cost 18.155514711219297\n",
      "Training MAE 3.491909271636424|test MAE 3.895360374449585\n",
      "Epochs74/500: \n",
      "Training cost 12.828451809891918|test cost 18.08052214405094\n",
      "Training MAE 3.4839988454136503|test MAE 3.8887308137035648\n",
      "Epochs75/500: \n",
      "Training cost 12.772185328128026|test cost 18.007301149890687\n",
      "Training MAE 3.4766107286620707|test MAE 3.882162583672891\n",
      "Epochs76/500: \n",
      "Training cost 12.717286630476208|test cost 17.935802187529507\n",
      "Training MAE 3.469673715020271|test MAE 3.875654990057348\n",
      "Epochs77/500: \n",
      "Training cost 12.663717032331451|test cost 17.865977288506887\n",
      "Training MAE 3.4629576410148|test MAE 3.8692073482018827\n",
      "Epochs78/500: \n",
      "Training cost 12.61143908580254|test cost 17.797780001973873\n",
      "Training MAE 3.456323228762006|test MAE 3.8628189829683772\n",
      "Epochs79/500: \n",
      "Training cost 12.560416535749463|test cost 17.73116534157959\n",
      "Training MAE 3.4497692677909084|test MAE 3.8564892286022596\n",
      "Epochs80/500: \n",
      "Training cost 12.510614277519375|test cost 17.666089734315786\n",
      "Training MAE 3.443294568156815|test MAE 3.850217428595365\n",
      "Epochs81/500: \n",
      "Training cost 12.461998316311467|test cost 17.602510971253263\n",
      "Training MAE 3.436897960064598|test MAE 3.8441351539788977\n",
      "Epochs82/500: \n",
      "Training cost 12.414535728104145|test cost 17.5403881601053\n",
      "Training MAE 3.430673140349004|test MAE 3.838204083463053\n",
      "Epochs83/500: \n",
      "Training cost 12.368194622080626|test cost 17.479681679553313\n",
      "Training MAE 3.424647879374654|test MAE 3.8323239417602606\n",
      "Epochs84/500: \n",
      "Training cost 12.322944104491965|test cost 17.42035313527153\n",
      "Training MAE 3.4187655263395307|test MAE 3.8271480976174956\n",
      "Epochs85/500: \n",
      "Training cost 12.278754243898893|test cost 17.362365317588782\n",
      "Training MAE 3.412953042400153|test MAE 3.822115419144131\n",
      "Epochs86/500: \n",
      "Training cost 12.235596037736567|test cost 17.30568216072653\n",
      "Training MAE 3.4072094044656223|test MAE 3.817122316344465\n",
      "Epochs87/500: \n",
      "Training cost 12.19344138014851|test cost 17.25026870355462\n",
      "Training MAE 3.401533606672903|test MAE 3.8121684561906233\n",
      "Epochs88/500: \n",
      "Training cost 12.152263031038368|test cost 17.19609105180712\n",
      "Training MAE 3.395924660067025|test MAE 3.8073056360831767\n",
      "Epochs89/500: \n",
      "Training cost 12.112034586290346|test cost 17.143116341703042\n",
      "Training MAE 3.390450528463669|test MAE 3.8025026664770873\n",
      "Epochs90/500: \n",
      "Training cost 12.07273044911116|test cost 17.09131270491805\n",
      "Training MAE 3.385467691972521|test MAE 3.797736986981735\n",
      "Epochs91/500: \n",
      "Training cost 12.034325802448327|test cost 17.040649234855245\n",
      "Training MAE 3.3806821625481858|test MAE 3.7930462777726484\n",
      "Epochs92/500: \n",
      "Training cost 11.996796582441624|test cost 16.991095954165004\n",
      "Training MAE 3.375951958529949|test MAE 3.788401427135211\n",
      "Epochs93/500: \n",
      "Training cost 11.960119452866268|test cost 16.94262378346536\n",
      "Training MAE 3.371365351314319|test MAE 3.783791513644072\n",
      "Epochs94/500: \n",
      "Training cost 11.92427178052813|test cost 16.89520451121641\n",
      "Training MAE 3.3668661654651366|test MAE 3.7793969072649234\n",
      "Epochs95/500: \n",
      "Training cost 11.889231611572962|test cost 16.84881076470383\n",
      "Training MAE 3.362417352438799|test MAE 3.7751014401163623\n",
      "Epochs96/500: \n",
      "Training cost 11.854977648673241|test cost 16.803415982088385\n",
      "Training MAE 3.3580395470587545|test MAE 3.770837795808153\n",
      "Epochs97/500: \n",
      "Training cost 11.821489229057715|test cost 16.75899438547975\n",
      "Training MAE 3.353844383205563|test MAE 3.7666056995078963\n",
      "Epochs98/500: \n",
      "Training cost 11.788746303350157|test cost 16.715520954994794\n",
      "Training MAE 3.3497184261924318|test MAE 3.7624048791880367\n",
      "Epochs99/500: \n",
      "Training cost 11.756729415185385|test cost 16.672971403761938\n",
      "Training MAE 3.345637620775482|test MAE 3.758235065584353\n",
      "Epochs100/500: \n",
      "Training cost 11.725419681571731|test cost 16.63132215383468\n",
      "Training MAE 3.341601341319961|test MAE 3.754095992155314\n",
      "Epochs101/500: \n",
      "Training cost 11.69479877397056|test cost 16.590550312978795\n",
      "Training MAE 3.337608972300456|test MAE 3.7500189146416694\n",
      "Epochs102/500: \n",
      "Training cost 11.664848900064646|test cost 16.550633652299304\n",
      "Training MAE 3.333886769921501|test MAE 3.746169348442955\n",
      "Epochs103/500: \n",
      "Training cost 11.635552786188319|test cost 16.511550584674488\n",
      "Training MAE 3.330224264436686|test MAE 3.7423476166118257\n",
      "Epochs104/500: \n",
      "Training cost 11.606893660393478|test cost 16.473280143965564\n",
      "Training MAE 3.3266015322134286|test MAE 3.738559275866801\n",
      "Epochs105/500: \n",
      "Training cost 11.578855236126598|test cost 16.43580196497198\n",
      "Training MAE 3.3230180189731717|test MAE 3.734806677521982\n",
      "Epochs106/500: \n",
      "Training cost 11.551421696492937|test cost 16.399096264103385\n",
      "Training MAE 3.3194731794429146|test MAE 3.731081116701159\n",
      "Epochs107/500: \n",
      "Training cost 11.524577679085054|test cost 16.363143820740646\n",
      "Training MAE 3.315966477191429|test MAE 3.7273823620857316\n",
      "Epochs108/500: \n",
      "Training cost 11.498308261353744|test cost 16.32792595925917\n",
      "Training MAE 3.312497384468685|test MAE 3.723710184769961\n",
      "Epochs109/500: \n",
      "Training cost 11.472598946500385|test cost 16.293424531689144\n",
      "Training MAE 3.3090653820484324|test MAE 3.720064358223305\n",
      "Epochs110/500: \n",
      "Training cost 11.447435649870565|test cost 16.259621900988115\n",
      "Training MAE 3.305743903104957|test MAE 3.716444658253653\n",
      "Epochs111/500: \n",
      "Training cost 11.42280468582962|test cost 16.226500924902435\n",
      "Training MAE 3.3025816009701487|test MAE 3.7128508629714103\n",
      "Epochs112/500: \n",
      "Training cost 11.398692755101607|test cost 16.194044940395017\n",
      "Training MAE 3.2995274423798784|test MAE 3.7094213879494675\n",
      "Epochs113/500: \n",
      "Training cost 11.375086932553883|test cost 16.162237748617766\n",
      "Training MAE 3.296516432371977|test MAE 3.706064784809389\n",
      "Epochs114/500: \n",
      "Training cost 11.351974655410277|test cost 16.131063600407906\n",
      "Training MAE 3.293536657930378|test MAE 3.702797552967608\n",
      "Epochs115/500: \n",
      "Training cost 11.329343711876472|test cost 16.100507182288297\n",
      "Training MAE 3.2905865262265688|test MAE 3.6995510215948064\n",
      "Epochs116/500: \n",
      "Training cost 11.307182230161901|test cost 16.070553602952618\n",
      "Training MAE 3.2877348817669088|test MAE 3.6963250522764195\n",
      "Epochs117/500: \n",
      "Training cost 11.285478667883117|test cost 16.041188380217022\n",
      "Training MAE 3.2850630088305963|test MAE 3.6931195074233996\n",
      "Epochs118/500: \n",
      "Training cost 11.264221801834152|test cost 16.012397428420766\n",
      "Training MAE 3.282460162290588|test MAE 3.6899342502661154\n",
      "Epochs119/500: \n",
      "Training cost 11.243400718110031|test cost 15.984167046258737\n",
      "Training MAE 3.2798822131426646|test MAE 3.6867691448484736\n",
      "Epochs120/500: \n",
      "Training cost 11.223004802570111|test cost 15.956483905029838\n",
      "Training MAE 3.277328846759113|test MAE 3.6836240560222095\n",
      "Epochs121/500: \n",
      "Training cost 11.203023731628468|test cost 15.929335037285531\n",
      "Training MAE 3.274799753271066|test MAE 3.680498849441361\n",
      "Epochs122/500: \n",
      "Training cost 11.183447463359085|test cost 15.90270782586365\n",
      "Training MAE 3.2722946274858176|test MAE 3.677393391556915\n",
      "Epochs123/500: \n",
      "Training cost 11.164266228904074|test cost 15.876589993293097\n",
      "Training MAE 3.269813168805715|test MAE 3.674307549611618\n",
      "Epochs124/500: \n",
      "Training cost 11.145470524173586|test cost 15.850969591555693\n",
      "Training MAE 3.267412878752825|test MAE 3.671241191634942\n",
      "Epochs125/500: \n",
      "Training cost 11.127051101826636|test cost 15.825834992191883\n",
      "Training MAE 3.2650393856013062|test MAE 3.6681941864381926\n",
      "Epochs126/500: \n",
      "Training cost 11.108998963522364|test cost 15.801174876737681\n",
      "Training MAE 3.262687653254394|test MAE 3.665371424401728\n",
      "Epochs127/500: \n",
      "Training cost 11.091305352431746|test cost 15.776978227480583\n",
      "Training MAE 3.260357418907462|test MAE 3.662653424477998\n",
      "Epochs128/500: \n",
      "Training cost 11.073961746000156|test cost 15.753234318522756\n",
      "Training MAE 3.258048423559984|test MAE 3.659951364329827\n",
      "Epochs129/500: \n",
      "Training cost 11.05695984895156|test cost 15.729932707140263\n",
      "Training MAE 3.255760411951704|test MAE 3.6572651491420283\n",
      "Epochs130/500: \n",
      "Training cost 11.040291586525454|test cost 15.707063225427532\n",
      "Training MAE 3.2534931325000134|test MAE 3.6545946844803794\n",
      "Epochs131/500: \n",
      "Training cost 11.023949097938058|test cost 15.684615972216626\n",
      "Training MAE 3.2512463372385123|test MAE 3.6519398762919595\n",
      "Epochs132/500: \n",
      "Training cost 11.007924730059571|test cost 15.662581305261403\n",
      "Training MAE 3.2491215095228916|test MAE 3.64930063090555\n",
      "Epochs133/500: \n",
      "Training cost 10.992211031299652|test cost 15.640949833676938\n",
      "Training MAE 3.2470717552171844|test MAE 3.646699506113208\n",
      "Epochs134/500: \n",
      "Training cost 10.976800745693549|test cost 15.619712410625079\n",
      "Training MAE 3.2450401135553086|test MAE 3.6443018380723613\n",
      "Epochs135/500: \n",
      "Training cost 10.96168680718165|test cost 15.598860126237131\n",
      "Training MAE 3.243179006116546|test MAE 3.6419169384506733\n",
      "Epochs136/500: \n",
      "Training cost 10.946862334075451|test cost 15.578384300765356\n",
      "Training MAE 3.241410993685136|test MAE 3.6395447517908517\n",
      "Epochs137/500: \n",
      "Training cost 10.932320623703315|test cost 15.558276477954951\n",
      "Training MAE 3.2396948973605384|test MAE 3.6371852223917633\n",
      "Epochs138/500: \n",
      "Training cost 10.918055147229444|test cost 15.5385284186288\n",
      "Training MAE 3.237997024488826|test MAE 3.63483829432109\n",
      "Epochs139/500: \n",
      "Training cost 10.904059544640042|test cost 15.519132094477266\n",
      "Training MAE 3.2364169893140255|test MAE 3.632503911427757\n",
      "Epochs140/500: \n",
      "Training cost 10.89032761989058|test cost 15.500079682045936\n",
      "Training MAE 3.2348681519957343|test MAE 3.6301820173541404\n",
      "Epochs141/500: \n",
      "Training cost 10.876853336208539|test cost 15.481363556914228\n",
      "Training MAE 3.2333519334729868|test MAE 3.627872555548041\n",
      "Epochs142/500: \n",
      "Training cost 10.863630811546026|test cost 15.462976288058218\n",
      "Training MAE 3.2318482631277248|test MAE 3.6255754692744433\n",
      "Epochs143/500: \n",
      "Training cost 10.850654314177104|test cost 15.444910632391132\n",
      "Training MAE 3.2303569934796084|test MAE 3.6232907016270546\n",
      "Epochs144/500: \n",
      "Training cost 10.837918258434614|test cost 15.4271595294754\n",
      "Training MAE 3.22887797922579|test MAE 3.6210181955396252\n",
      "Epochs145/500: \n",
      "Training cost 10.825417200581697|test cost 15.409716096400237\n",
      "Training MAE 3.2274110772030697|test MAE 3.6187578937970497\n",
      "Epochs146/500: \n",
      "Training cost 10.813145834813245|test cost 15.392573622819018\n",
      "Training MAE 3.2259561463507658|test MAE 3.616509739046263\n",
      "Epochs147/500: \n",
      "Training cost 10.801098989382787|test cost 15.375725566140924\n",
      "Training MAE 3.224558237550512|test MAE 3.614273673806918\n",
      "Epochs148/500: \n",
      "Training cost 10.789271622850439|test cost 15.359165546871516\n",
      "Training MAE 3.223226095233961|test MAE 3.612049640481857\n",
      "Epochs149/500: \n",
      "Training cost 10.777658820447728|test cost 15.342887344097178\n",
      "Training MAE 3.2219370809875123|test MAE 3.609837581367378\n",
      "Epochs150/500: \n",
      "Training cost 10.76625579055525|test cost 15.326884891108378\n",
      "Training MAE 3.2207340232973194|test MAE 3.6076374386632937\n",
      "Epochs151/500: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost 10.755057861289298|test cost 15.311152271157184\n",
      "Training MAE 3.2195667251290767|test MAE 3.6054491544827907\n",
      "Epochs152/500: \n",
      "Training cost 10.744060477193706|test cost 15.2956837133443\n",
      "Training MAE 3.21840767444341|test MAE 3.6032726708620837\n",
      "Epochs153/500: \n",
      "Training cost 10.733259196033291|test cost 15.280473588631342\n",
      "Training MAE 3.2172567842698605|test MAE 3.601107929769881\n",
      "Epochs154/500: \n",
      "Training cost 10.722649685685509|test cost 15.26551640597403\n",
      "Training MAE 3.2161139688432216|test MAE 3.598954873116646\n",
      "Epochs155/500: \n",
      "Training cost 10.712227721126883|test cost 15.250806808572326\n",
      "Training MAE 3.2149791435832413|test MAE 3.596813442763673\n",
      "Epochs156/500: \n",
      "Training cost 10.70198918151109|test cost 15.236339570233511\n",
      "Training MAE 3.2138604964921047|test MAE 3.5946835805319663\n",
      "Epochs157/500: \n",
      "Training cost 10.691930047335543|test cost 15.222109591844449\n",
      "Training MAE 3.212881124408655|test MAE 3.5925652282109315\n",
      "Epochs158/500: \n",
      "Training cost 10.682046397693536|test cost 15.208111897949394\n",
      "Training MAE 3.211962700373976|test MAE 3.5904583275668873\n",
      "Epochs159/500: \n",
      "Training cost 10.672334407609076|test cost 15.194341633429868\n",
      "Training MAE 3.2110863645683274|test MAE 3.588362820351385\n",
      "Epochs160/500: \n",
      "Training cost 10.662790345451612|test cost 15.180794060283164\n",
      "Training MAE 3.210274479680644|test MAE 3.586343766517266\n",
      "Epochs161/500: \n",
      "Training cost 10.653410570428052|test cost 15.167464554496265\n",
      "Training MAE 3.209550562927981|test MAE 3.584369867517129\n",
      "Epochs162/500: \n",
      "Training cost 10.64419153014944|test cost 15.154348603012052\n",
      "Training MAE 3.208839580886909|test MAE 3.5824058395492893\n",
      "Epochs163/500: \n",
      "Training cost 10.635129758269887|test cost 15.141441800784728\n",
      "Training MAE 3.2081575919997825|test MAE 3.5804516484285784\n",
      "Epochs164/500: \n",
      "Training cost 10.626221872195327|test cost 15.128739847921592\n",
      "Training MAE 3.207478614602352|test MAE 3.5785072595236294\n",
      "Epochs165/500: \n",
      "Training cost 10.617464570859816|test cost 15.116238546908344\n",
      "Training MAE 3.2068026262147957|test MAE 3.576572637773804\n",
      "Epochs166/500: \n",
      "Training cost 10.608854632567203|test cost 15.103933799915147\n",
      "Training MAE 3.2061296046682086|test MAE 3.574647747705747\n",
      "Epochs167/500: \n",
      "Training cost 10.60038891289595|test cost 15.091821606180963\n",
      "Training MAE 3.2054595280984373|test MAE 3.5727325534495695\n",
      "Epochs168/500: \n",
      "Training cost 10.592064342665134|test cost 15.07989805947352\n",
      "Training MAE 3.204792374940041|test MAE 3.5708270187546933\n",
      "Epochs169/500: \n",
      "Training cost 10.58387792595964|test cost 15.06815934562255\n",
      "Training MAE 3.204128123920401|test MAE 3.5689311070053114\n",
      "Epochs170/500: \n",
      "Training cost 10.575826738212545|test cost 15.056601740123941\n",
      "Training MAE 3.2034667540539474|test MAE 3.567044781235533\n",
      "Epochs171/500: \n",
      "Training cost 10.567907924342967|test cost 15.045221605812507\n",
      "Training MAE 3.2028082446365214|test MAE 3.5651680041441773\n",
      "Epochs172/500: \n",
      "Training cost 10.56011869694753|test cost 15.034015390601272\n",
      "Training MAE 3.2021525752398596|test MAE 3.5633007381092283\n",
      "Epochs173/500: \n",
      "Training cost 10.552456334543757|test cost 15.022979625285084\n",
      "Training MAE 3.2014997257062|test MAE 3.561442945201977\n",
      "Epochs174/500: \n",
      "Training cost 10.544918179863698|test cost 15.012110921406558\n",
      "Training MAE 3.200849676143005|test MAE 3.5595945872008317\n",
      "Epochs175/500: \n",
      "Training cost 10.537501638196277|test cost 15.001405969182454\n",
      "Training MAE 3.200202406917807|test MAE 3.5577556256048206\n",
      "Epochs176/500: \n",
      "Training cost 10.530204175776715|test cost 14.99086153548844\n",
      "Training MAE 3.19955789865316|test MAE 3.5559260216467767\n",
      "Epochs177/500: \n",
      "Training cost 10.523023318221634|test cost 14.98047446190059\n",
      "Training MAE 3.198916132221712|test MAE 3.554105736306236\n",
      "Epochs178/500: \n",
      "Training cost 10.515956649008348|test cost 14.970241662791755\n",
      "Training MAE 3.198334712171758|test MAE 3.5522947303220214\n",
      "Epochs179/500: \n",
      "Training cost 10.509001807996977|test cost 14.960160123481097\n",
      "Training MAE 3.1977600861275617|test MAE 3.5504929642045404\n",
      "Epochs180/500: \n",
      "Training cost 10.50215648999405|test cost 14.950226898435226\n",
      "Training MAE 3.1971872082972985|test MAE 3.548700398247805\n",
      "Epochs181/500: \n",
      "Training cost 10.495418443356295|test cost 14.940439109519234\n",
      "Training MAE 3.1966593517740876|test MAE 3.5469899017009845\n",
      "Epochs182/500: \n",
      "Training cost 10.48878546863339|test cost 14.930793944296203\n",
      "Training MAE 3.1961348998610504|test MAE 3.545370120931888\n",
      "Epochs183/500: \n",
      "Training cost 10.482255417248442|test cost 14.921288654373653\n",
      "Training MAE 3.1956115605475666|test MAE 3.543758492481477\n",
      "Epochs184/500: \n",
      "Training cost 10.475826190215058|test cost 14.91192055379548\n",
      "Training MAE 3.1950893408836123|test MAE 3.5421549832614216\n",
      "Epochs185/500: \n",
      "Training cost 10.469495736889861|test cost 14.902687017478062\n",
      "Training MAE 3.1945691307650614|test MAE 3.5405595599729027\n",
      "Epochs186/500: \n",
      "Training cost 10.463262053759399|test cost 14.89358547968911\n",
      "Training MAE 3.194055114073111|test MAE 3.539091817369528\n",
      "Epochs187/500: \n",
      "Training cost 10.457123183260357|test cost 14.884613432568102\n",
      "Training MAE 3.1935422556399082|test MAE 3.537678135025792\n",
      "Epochs188/500: \n",
      "Training cost 10.451077212632098|test cost 14.875768424686877\n",
      "Training MAE 3.1930305589448458|test MAE 3.5363681502034443\n",
      "Epochs189/500: \n",
      "Training cost 10.445122272800518|test cost 14.867048059649374\n",
      "Training MAE 3.19252002735195|test MAE 3.53508359611982\n",
      "Epochs190/500: \n",
      "Training cost 10.439256537292323|test cost 14.858449994729188\n",
      "Training MAE 3.1920116699445202|test MAE 3.533804911302611\n",
      "Epochs191/500: \n",
      "Training cost 10.433478221178738|test cost 14.849971939543893\n",
      "Training MAE 3.191518634847808|test MAE 3.5325320833413767\n",
      "Epochs192/500: \n",
      "Training cost 10.427785580047836|test cost 14.841611654765067\n",
      "Training MAE 3.1910266191690755|test MAE 3.5312650994462906\n",
      "Epochs193/500: \n",
      "Training cost 10.422176909004584|test cost 14.833366950862876\n",
      "Training MAE 3.1905356276733876|test MAE 3.5300039464591086\n",
      "Epochs194/500: \n",
      "Training cost 10.416650541697816|test cost 14.825235686884282\n",
      "Training MAE 3.1900456649907314|test MAE 3.5287654010649896\n",
      "Epochs195/500: \n",
      "Training cost 10.41120484937329|test cost 14.817215769263848\n",
      "Training MAE 3.1895567356180656|test MAE 3.527547228290078\n",
      "Epochs196/500: \n",
      "Training cost 10.405838239952105|test cost 14.809305150666157\n",
      "Training MAE 3.189098129702057|test MAE 3.5263352009487314\n",
      "Epochs197/500: \n",
      "Training cost 10.40054915713372|test cost 14.801501828859015\n",
      "Training MAE 3.1886545642562236|test MAE 3.525129299973449\n",
      "Epochs198/500: \n",
      "Training cost 10.395336079522778|test cost 14.793803845616436\n",
      "Training MAE 3.1882225750697297|test MAE 3.5239295060357403\n",
      "Epochs199/500: \n",
      "Training cost 10.390197519779182|test cost 14.786209285650589\n",
      "Training MAE 3.1878010319836996|test MAE 3.52273579955494\n",
      "Epochs200/500: \n",
      "Training cost 10.385132023790602|test cost 14.778716275571904\n",
      "Training MAE 3.187379939899632|test MAE 3.5215481607068617\n",
      "Epochs201/500: \n",
      "Training cost 10.380138169866838|test cost 14.771322982876477\n",
      "Training MAE 3.1869593110262717|test MAE 3.520366569432261\n",
      "Epochs202/500: \n",
      "Training cost 10.375214567955389|test cost 14.764027614959996\n",
      "Training MAE 3.1865391573083626|test MAE 3.519191005445129\n",
      "Epochs203/500: \n",
      "Training cost 10.370359858877602|test cost 14.756828418157436\n",
      "Training MAE 3.1861497469332165|test MAE 3.5180214482408245\n",
      "Epochs204/500: \n",
      "Training cost 10.365572713584834|test cost 14.749723676807815\n",
      "Training MAE 3.18581882729222|test MAE 3.5168578771040235\n",
      "Epochs205/500: \n",
      "Training cost 10.360851832434006|test cost 14.742711712343256\n",
      "Training MAE 3.1854876469985918|test MAE 3.5157002711165224\n",
      "Epochs206/500: \n",
      "Training cost 10.356195944482057|test cost 14.735790882401641\n",
      "Training MAE 3.1851702044513965|test MAE 3.514548609164857\n",
      "Epochs207/500: \n",
      "Training cost 10.351603806798682|test cost 14.728959579962323\n",
      "Training MAE 3.1848543949560826|test MAE 3.5134028699477904\n",
      "Epochs208/500: \n",
      "Training cost 10.347074203796925|test cost 14.722216232504035\n",
      "Training MAE 3.1845382663023725|test MAE 3.5122630319836237\n",
      "Epochs209/500: \n",
      "Training cost 10.342605946581022|test cost 14.715559301184596\n",
      "Training MAE 3.184221835509193|test MAE 3.5111290736173535\n",
      "Epochs210/500: \n",
      "Training cost 10.338197872311078|test cost 14.708987280041601\n",
      "Training MAE 3.18390511933037|test MAE 3.5100009730276986\n",
      "Epochs211/500: \n",
      "Training cost 10.333848843584075|test cost 14.702498695213679\n",
      "Training MAE 3.183588134258332|test MAE 3.508878708233952\n",
      "Epochs212/500: \n",
      "Training cost 10.329557747830771|test cost 14.696092104181611\n",
      "Training MAE 3.183270896527754|test MAE 3.507762257102713\n",
      "Epochs213/500: \n",
      "Training cost 10.32532349672798|test cost 14.689766095028853\n",
      "Training MAE 3.1829534221191498|test MAE 3.506651597354454\n",
      "Epochs214/500: \n",
      "Training cost 10.321145025625913|test cost 14.683519285720866\n",
      "Training MAE 3.1826357267624164|test MAE 3.5055467065699593\n",
      "Epochs215/500: \n",
      "Training cost 10.317021292990065|test cost 14.677350323402742\n",
      "Training MAE 3.1823178259403275|test MAE 3.504447562196629\n",
      "Epochs216/500: \n",
      "Training cost 10.312951279857275|test cost 14.671257883714663\n",
      "Training MAE 3.1820057503168746|test MAE 3.503372284924355\n",
      "Epochs217/500: \n",
      "Training cost 10.308933989305592|test cost 14.665240670124657\n",
      "Training MAE 3.1816994081989787|test MAE 3.5023543708247336\n",
      "Epochs218/500: \n",
      "Training cost 10.304968445937519|test cost 14.65929741327821\n",
      "Training MAE 3.1813956199109374|test MAE 3.501341458397303\n",
      "Epochs219/500: \n",
      "Training cost 10.301053695376304|test cost 14.653426870364195\n",
      "Training MAE 3.181095122548223|test MAE 3.500333531814199\n",
      "Epochs220/500: \n",
      "Training cost 10.297188803774914|test cost 14.647627824496833\n",
      "Training MAE 3.180794244037087|test MAE 3.4993305750587527\n",
      "Epochs221/500: \n",
      "Training cost 10.293372857337312|test cost 14.641899084113074\n",
      "Training MAE 3.180493002523482|test MAE 3.498332571932156\n",
      "Epochs222/500: \n",
      "Training cost 10.28960496185176|test cost 14.63623948238509\n",
      "Training MAE 3.180191415852747|test MAE 3.4973395060599906\n",
      "Epochs223/500: \n",
      "Training cost 10.285884242235747|test cost 14.630647876647435\n",
      "Training MAE 3.179889501574274|test MAE 3.4963513608986188\n",
      "Epochs224/500: \n",
      "Training cost 10.282209842092305|test cost 14.625123147838478\n",
      "Training MAE 3.1795872769460907|test MAE 3.495386935861954\n",
      "Epochs225/500: \n",
      "Training cost 10.278580923277337|test cost 14.619664199955727\n",
      "Training MAE 3.1792847589393882|test MAE 3.494471589704168\n",
      "Epochs226/500: \n",
      "Training cost 10.274996665477714|test cost 14.614269959524687\n",
      "Training MAE 3.1789819642429467|test MAE 3.493560466180097\n",
      "Epochs227/500: \n",
      "Training cost 10.271456265799795|test cost 14.608939375080867\n",
      "Training MAE 3.1787062195406373|test MAE 3.4926535560362315\n",
      "Epochs228/500: \n",
      "Training cost 10.267958938368153|test cost 14.603671416664577\n",
      "Training MAE 3.1784457223701588|test MAE 3.491750849768189\n",
      "Epochs229/500: \n",
      "Training cost 10.264503913934185|test cost 14.59846507532822\n",
      "Training MAE 3.1781847652204442|test MAE 3.490852337628132\n",
      "Epochs230/500: \n",
      "Training cost 10.261090439494348|test cost 14.5933193626557\n",
      "Training MAE 3.177923366138252|test MAE 3.4899580096319993\n",
      "Epochs231/500: \n",
      "Training cost 10.2577177779178|test cost 14.588233310293651\n",
      "Training MAE 3.177661542873521|test MAE 3.489067855566627\n",
      "Epochs232/500: \n",
      "Training cost 10.254385207583164|test cost 14.583205969494177\n",
      "Training MAE 3.1773993128839786|test MAE 3.4881818649966827\n",
      "Epochs233/500: \n",
      "Training cost 10.251092022024158|test cost 14.578236410668751\n",
      "Training MAE 3.177136693339678|test MAE 3.4873000272714965\n",
      "Epochs234/500: \n",
      "Training cost 10.247837529583922|test cost 14.573323722953088\n",
      "Training MAE 3.176880757309112|test MAE 3.486422331531701\n",
      "Epochs235/500: \n",
      "Training cost 10.244621053077735|test cost 14.568467013782563\n",
      "Training MAE 3.1766261419909965|test MAE 3.4855487667157856\n",
      "Epochs236/500: \n",
      "Training cost 10.24144192946394|test cost 14.563665408478023\n",
      "Training MAE 3.176371152181614|test MAE 3.4846793215664738\n",
      "Epochs237/500: \n",
      "Training cost 10.238299509522895|test cost 14.558918049841644\n",
      "Training MAE 3.1761158050420666|test MAE 3.483813984636981\n",
      "Epochs238/500: \n",
      "Training cost 10.235193157543648|test cost 14.554224097762578\n",
      "Training MAE 3.1758601174358936|test MAE 3.4829527442971466\n",
      "Epochs239/500: \n",
      "Training cost 10.232122251018243|test cost 14.549582728832236\n",
      "Training MAE 3.1756041059339433|test MAE 3.482095588739427\n",
      "Epochs240/500: \n",
      "Training cost 10.229086180343366|test cost 14.544993135968747\n",
      "Training MAE 3.1753477868191524|test MAE 3.4812425059847643\n",
      "Epochs241/500: \n",
      "Training cost 10.226084348529204|test cost 14.5404545280506\n",
      "Training MAE 3.1750911760912506|test MAE 3.4803934838883364\n",
      "Epochs242/500: \n",
      "Training cost 10.223116170915311|test cost 14.535966129559066\n",
      "Training MAE 3.17483428947138|test MAE 3.479623986181669\n",
      "Epochs243/500: \n",
      "Training cost 10.220181074893262|test cost 14.531527180229212\n",
      "Training MAE 3.1745771424066365|test MAE 3.47893558521719\n",
      "Epochs244/500: \n",
      "Training cost 10.217278499635999|test cost 14.527136934709324\n",
      "Training MAE 3.1743197500745315|test MAE 3.478250274662728\n",
      "Epochs245/500: \n",
      "Training cost 10.214407895833611|test cost 14.522794662228488\n",
      "Training MAE 3.1740621273873835|test MAE 3.4775708774095127\n",
      "Epochs246/500: \n",
      "Training cost 10.211568725435457|test cost 14.518499646272142\n",
      "Training MAE 3.1738042889966254|test MAE 3.476993491159388\n",
      "Epochs247/500: \n",
      "Training cost 10.208760461398413|test cost 14.51425118426535\n",
      "Training MAE 3.1735462492970443|test MAE 3.476418505623547\n",
      "Epochs248/500: \n",
      "Training cost 10.205982587441122|test cost 14.510048587263666\n",
      "Training MAE 3.173288022430951|test MAE 3.4758459212261963\n",
      "Epochs249/500: \n",
      "Training cost 10.203234597804071|test cost 14.505891179651371\n",
      "Training MAE 3.173029622292272|test MAE 3.4752757381378805\n",
      "Epochs250/500: \n",
      "Training cost 10.200515997015382|test cost 14.501778298846846\n",
      "Training MAE 3.1727786708541825|test MAE 3.474707956281439\n",
      "Epochs251/500: \n",
      "Training cost 10.197826299662122|test cost 14.49770929501499\n",
      "Training MAE 3.1725597858927173|test MAE 3.4741425753378365\n",
      "Epochs252/500: \n",
      "Training cost 10.195165030167022|test cost 14.493683530786424\n",
      "Training MAE 3.1723405141270407|test MAE 3.473579594751887\n",
      "Epochs253/500: \n",
      "Training cost 10.192531722570493|test cost 14.489700380983372\n",
      "Training MAE 3.172132424125354|test MAE 3.4730190137378636\n",
      "Epochs254/500: \n",
      "Training cost 10.189925920317732|test cost 14.485759232351992\n",
      "Training MAE 3.1719332711978034|test MAE 3.4724608312850203\n",
      "Epochs255/500: \n",
      "Training cost 10.187347176050876|test cost 14.481859483301049\n",
      "Training MAE 3.1717335771307176|test MAE 3.4719050461629783\n",
      "Epochs256/500: \n",
      "Training cost 10.184795051406027|test cost 14.478000543646761\n",
      "Training MAE 3.1715333586907195|test MAE 3.4713516569270326\n",
      "Epochs257/500: \n",
      "Training cost 10.182269116815007|test cost 14.474181834363598\n",
      "Training MAE 3.1713326323787023|test MAE 3.4708006619233487\n",
      "Epochs258/500: \n",
      "Training cost 10.179768951311807|test cost 14.470402787340982\n",
      "Training MAE 3.171131414433842|test MAE 3.4702520592940576\n",
      "Epochs259/500: \n",
      "Training cost 10.177294142343504|test cost 14.466662845145697\n",
      "Training MAE 3.170929720837543|test MAE 3.4697058469822566\n",
      "Epochs260/500: \n",
      "Training cost 10.17484428558564|test cost 14.462961460789847\n",
      "Training MAE 3.1707275673173285|test MAE 3.4691620227369144\n",
      "Epochs261/500: \n",
      "Training cost 10.172418984761867|test cost 14.459298097504231\n",
      "Training MAE 3.1705249693506636|test MAE 3.4686205841176734\n",
      "Epochs262/500: \n",
      "Training cost 10.170017851467806|test cost 14.455672228517075\n",
      "Training MAE 3.1703219421687163|test MAE 3.468113956317093\n",
      "Epochs263/500: \n",
      "Training cost 10.167640504999005|test cost 14.452083336837847\n",
      "Training MAE 3.170118500760065|test MAE 3.4677146634062366\n",
      "Epochs264/500: \n",
      "Training cost 10.165286572182854|test cost 14.448530915046149\n",
      "Training MAE 3.169934546101085|test MAE 3.4673164989468566\n",
      "Epochs265/500: \n",
      "Training cost 10.162955687214442|test cost 14.44501446508555\n",
      "Training MAE 3.169751918828343|test MAE 3.46691947216455\n",
      "Epochs266/500: \n",
      "Training cost 10.160647491496178|test cost 14.441533498062142\n",
      "Training MAE 3.169569664340273|test MAE 3.4665235919994215\n",
      "Epochs267/500: \n",
      "Training cost 10.15836163348112|test cost 14.438087534047833\n",
      "Training MAE 3.1693953650725413|test MAE 3.466128867111329\n",
      "Epochs268/500: \n",
      "Training cost 10.156097768519924|test cost 14.434676101888131\n",
      "Training MAE 3.169220405064187|test MAE 3.4657353058850466\n",
      "Epochs269/500: \n",
      "Training cost 10.153855558711324|test cost 14.431298739014462\n",
      "Training MAE 3.1690538678630062|test MAE 3.4653429164353495\n",
      "Epochs270/500: \n",
      "Training cost 10.151634672756034|test cost 14.427954991260744\n",
      "Training MAE 3.1688955407238506|test MAE 3.4649517066119975\n",
      "Epochs271/500: \n",
      "Training cost 10.149434785814023|test cost 14.424644412684243\n",
      "Training MAE 3.168736562996314|test MAE 3.4645616840046514\n",
      "Epochs272/500: \n",
      "Training cost 10.147255579365053|test cost 14.42136656539053\n",
      "Training MAE 3.1685769513831596|test MAE 3.4641728559477007\n",
      "Epochs273/500: \n",
      "Training cost 10.145096741072408|test cost 14.418121019362484\n",
      "Training MAE 3.16841672232991|test MAE 3.4637852295250124\n",
      "Epochs274/500: \n",
      "Training cost 10.142957964649758|test cost 14.414907352293222\n",
      "Training MAE 3.168255892028674|test MAE 3.4633988115745984\n",
      "Epochs275/500: \n",
      "Training cost 10.140838949731046|test cost 14.41172514942285\n",
      "Training MAE 3.168094476421901|test MAE 3.4630136086932075\n",
      "Epochs276/500: \n",
      "Training cost 10.138739401743356|test cost 14.408574003378968\n",
      "Training MAE 3.1679324912060807|test MAE 3.462629627240841\n",
      "Epochs277/500: \n",
      "Training cost 10.136659031782656|test cost 14.40545351402085\n",
      "Training MAE 3.167769951835386|test MAE 3.462246873345192\n",
      "Epochs278/500: \n",
      "Training cost 10.13459755649241|test cost 14.402363288287114\n",
      "Training MAE 3.167606873525258|test MAE 3.4618708328968957\n",
      "Epochs279/500: \n",
      "Training cost 10.132554697944903|test cost 14.399302940046963\n",
      "Training MAE 3.1674432712559377|test MAE 3.461506597031153\n",
      "Epochs280/500: \n",
      "Training cost 10.130530183525279|test cost 14.396272089954746\n",
      "Training MAE 3.1672791597759353|test MAE 3.4611432657340697\n",
      "Epochs281/500: \n",
      "Training cost 10.128523745818223|test cost 14.393270365307863\n",
      "Training MAE 3.1671145536054572|test MAE 3.4607808479646\n",
      "Epochs282/500: \n",
      "Training cost 10.126535122497177|test cost 14.390297399907904\n",
      "Training MAE 3.1669494670397653|test MAE 3.4604193524360807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs283/500: \n",
      "Training cost 10.124564056216089|test cost 14.387352833924938\n",
      "Training MAE 3.1667839141525027|test MAE 3.460058787620438\n",
      "Epochs284/500: \n",
      "Training cost 10.12261029450358|test cost 14.384436313764862\n",
      "Training MAE 3.1666179087989494|test MAE 3.4596991617523196\n",
      "Epochs285/500: \n",
      "Training cost 10.120673589659534|test cost 14.381547491939786\n",
      "Training MAE 3.166451464619238|test MAE 3.4593404828331895\n",
      "Epochs286/500: \n",
      "Training cost 10.118753698653965|test cost 14.378686026941331\n",
      "Training MAE 3.166284595041523|test MAE 3.4590071199823984\n",
      "Epochs287/500: \n",
      "Training cost 10.116850383028215|test cost 14.375851583116802\n",
      "Training MAE 3.1661173132850866|test MAE 3.4586790604073903\n",
      "Epochs288/500: \n",
      "Training cost 10.114963408798346|test cost 14.373043830548156\n",
      "Training MAE 3.165949632363415|test MAE 3.4583518761978724\n",
      "Epochs289/500: \n",
      "Training cost 10.113092546360686|test cost 14.37026244493368\n",
      "Training MAE 3.1657815650872148|test MAE 3.458028531755727\n",
      "Epochs290/500: \n",
      "Training cost 10.111237570399517|test cost 14.367507107472349\n",
      "Training MAE 3.165613124067386|test MAE 3.4577058706438684\n",
      "Epochs291/500: \n",
      "Training cost 10.109398259796821|test cost 14.364777504750807\n",
      "Training MAE 3.1654443217179544|test MAE 3.4573839033305025\n",
      "Epochs292/500: \n",
      "Training cost 10.10757439754405|test cost 14.36207332863283\n",
      "Training MAE 3.165275170258949|test MAE 3.457062640025119\n",
      "Epochs293/500: \n",
      "Training cost 10.105765770655841|test cost 14.359394276151315\n",
      "Training MAE 3.165105681719249|test MAE 3.456742090682886\n",
      "Epochs294/500: \n",
      "Training cost 10.10397217008571|test cost 14.356740049402683\n",
      "Training MAE 3.164935867939375|test MAE 3.456422265008971\n",
      "Epochs295/500: \n",
      "Training cost 10.102193390643556|test cost 14.354110355443627\n",
      "Training MAE 3.164765740574245|test MAE 3.4561031724627984\n",
      "Epochs296/500: \n",
      "Training cost 10.100429230915063|test cost 14.351504906190183\n",
      "Training MAE 3.164595311095885|test MAE 3.4557848222622405\n",
      "Epochs297/500: \n",
      "Training cost 10.09867949318285|test cost 14.348923418319039\n",
      "Training MAE 3.1644245907960973|test MAE 3.4554857843794844\n",
      "Epochs298/500: \n",
      "Training cost 10.096943983349412|test cost 14.346365613171063\n",
      "Training MAE 3.1642535907890967|test MAE 3.455250949403188\n",
      "Epochs299/500: \n",
      "Training cost 10.095222510861733|test cost 14.343831216656989\n",
      "Training MAE 3.164082322014096|test MAE 3.4550164888786883\n",
      "Epochs300/500: \n",
      "Training cost 10.09351488863758|test cost 14.341319959165128\n",
      "Training MAE 3.163910795237857|test MAE 3.4547824141429455\n",
      "Epochs301/500: \n",
      "Training cost 10.091820932993464|test cost 14.338831575471245\n",
      "Training MAE 3.1637390210572054|test MAE 3.454548736276436\n",
      "Epochs302/500: \n",
      "Training cost 10.090140463574128|test cost 14.336365804650324\n",
      "Training MAE 3.163567009901502|test MAE 3.454315466107481\n",
      "Epochs303/500: \n",
      "Training cost 10.088473303283658|test cost 14.333922389990372\n",
      "Training MAE 3.1633947720350832|test MAE 3.4540826142164964\n",
      "Epochs304/500: \n",
      "Training cost 10.086819278218073|test cost 14.331501078908069\n",
      "Training MAE 3.163231767699242|test MAE 3.4538501909401873\n",
      "Epochs305/500: \n",
      "Training cost 10.085178217599406|test cost 14.329101622866334\n",
      "Training MAE 3.1630746864722776|test MAE 3.4536182063756744\n",
      "Epochs306/500: \n",
      "Training cost 10.083549953711264|test cost 14.326723777293667\n",
      "Training MAE 3.162917324418716|test MAE 3.453386670384544\n",
      "Epochs307/500: \n",
      "Training cost 10.081934321835758|test cost 14.324367301505275\n",
      "Training MAE 3.162759691914152|test MAE 3.453155592596847\n",
      "Epochs308/500: \n",
      "Training cost 10.080331160191868|test cost 14.322031958626\n",
      "Training MAE 3.1626017991710698|test MAE 3.4529249824150288\n",
      "Epochs309/500: \n",
      "Training cost 10.078740309875126|test cost 14.319717515514826\n",
      "Training MAE 3.162443656241222|test MAE 3.4526948490177984\n",
      "Epochs310/500: \n",
      "Training cost 10.077161614798628|test cost 14.317423742691162\n",
      "Training MAE 3.162285273017986|test MAE 3.452465201363935\n",
      "Epochs311/500: \n",
      "Training cost 10.075594921635357|test cost 14.315150414262648\n",
      "Training MAE 3.162126659238662|test MAE 3.4522360481960335\n",
      "Epochs312/500: \n",
      "Training cost 10.074040079761744|test cost 14.312897307854602\n",
      "Training MAE 3.161967824486766|test MAE 3.4520073980441937\n",
      "Epochs313/500: \n",
      "Training cost 10.072496941202465|test cost 14.310664204540998\n",
      "Training MAE 3.1618126311069723|test MAE 3.451779259229651\n",
      "Epochs314/500: \n",
      "Training cost 10.070965360576464|test cost 14.308450888776925\n",
      "Training MAE 3.161680119254914|test MAE 3.4515516398683435\n",
      "Epochs315/500: \n",
      "Training cost 10.069445195044128|test cost 14.30625714833257\n",
      "Training MAE 3.1615473485670944|test MAE 3.4513245478744317\n",
      "Epochs316/500: \n",
      "Training cost 10.06793630425563|test cost 14.304082774228588\n",
      "Training MAE 3.161414327783907|test MAE 3.4510979909637527\n",
      "Epochs317/500: \n",
      "Training cost 10.066438550300383|test cost 14.301927560672915\n",
      "Training MAE 3.161281065512069|test MAE 3.450871976657231\n",
      "Epochs318/500: \n",
      "Training cost 10.064951797657601|test cost 14.299791304998946\n",
      "Training MAE 3.161147570226527|test MAE 3.4506465122842203\n",
      "Epochs319/500: \n",
      "Training cost 10.063475913147933|test cost 14.297673807605037\n",
      "Training MAE 3.1610138502723255|test MAE 3.4504216049858076\n",
      "Epochs320/500: \n",
      "Training cost 10.06201076588615|test cost 14.295574871895358\n",
      "Training MAE 3.160879913866459|test MAE 3.4501972617180563\n",
      "Epochs321/500: \n",
      "Training cost 10.060556227234839|test cost 14.293494304221976\n",
      "Training MAE 3.160745769099689|test MAE 3.449973489255195\n",
      "Epochs322/500: \n",
      "Training cost 10.059112170759127|test cost 14.291431913828259\n",
      "Training MAE 3.160611423938335|test MAE 3.449750294192766\n",
      "Epochs323/500: \n",
      "Training cost 10.057678472182358|test cost 14.289387512793423\n",
      "Training MAE 3.160476886226049|test MAE 3.449527682950713\n",
      "Epochs324/500: \n",
      "Training cost 10.05625500934275|test cost 14.287360915978345\n",
      "Training MAE 3.160342163685547|test MAE 3.449305661776426\n",
      "Epochs325/500: \n",
      "Training cost 10.054841662150972|test cost 14.285351940972493\n",
      "Training MAE 3.160207263920327|test MAE 3.4490842367477383\n",
      "Epochs326/500: \n",
      "Training cost 10.053438312548634|test cost 14.28336040804203\n",
      "Training MAE 3.1600721944163657|test MAE 3.448868449328157\n",
      "Epochs327/500: \n",
      "Training cost 10.052044844467689|test cost 14.281386140079034\n",
      "Training MAE 3.159936962543776|test MAE 3.4486605066229137\n",
      "Epochs328/500: \n",
      "Training cost 10.050661143790695|test cost 14.279428962551764\n",
      "Training MAE 3.159801575558454|test MAE 3.4484530255919763\n",
      "Epochs329/500: \n",
      "Training cost 10.04928709831192|test cost 14.277488703456072\n",
      "Training MAE 3.1596660406036956|test MAE 3.4482460137313415\n",
      "Epochs330/500: \n",
      "Training cost 10.047922597699321|test cost 14.275565193267768\n",
      "Training MAE 3.159530364711788|test MAE 3.448039478351744\n",
      "Epochs331/500: \n",
      "Training cost 10.046567533457281|test cost 14.27365826489606\n",
      "Training MAE 3.159394554805583|test MAE 3.4478334265818464\n",
      "Epochs332/500: \n",
      "Training cost 10.045221798890214|test cost 14.271767753637963\n",
      "Training MAE 3.1592586177000483|test MAE 3.4476278653713592\n",
      "Epochs333/500: \n",
      "Training cost 10.04388528906687|test cost 14.269893497133722\n",
      "Training MAE 3.1591225601037873|test MAE 3.4474228014941333\n",
      "Epochs334/500: \n",
      "Training cost 10.042557900785484|test cost 14.268035335323091\n",
      "Training MAE 3.1589863886205474|test MAE 3.4472182415511816\n",
      "Epochs335/500: \n",
      "Training cost 10.041239532539604|test cost 14.266193110402659\n",
      "Training MAE 3.1588501097507007|test MAE 3.4470141919736754\n",
      "Epochs336/500: \n",
      "Training cost 10.03993008448468|test cost 14.264366666783994\n",
      "Training MAE 3.1587137298927037|test MAE 3.4468106590258665\n",
      "Epochs337/500: \n",
      "Training cost 10.03862945840538|test cost 14.262555851052705\n",
      "Training MAE 3.1585772553445413|test MAE 3.446607648807984\n",
      "Epochs338/500: \n",
      "Training cost 10.03733755768355|test cost 14.2607605119284\n",
      "Training MAE 3.1584406923051382|test MAE 3.4464051672590745\n",
      "Epochs339/500: \n",
      "Training cost 10.036054287266913|test cost 14.258980500225405\n",
      "Training MAE 3.158304046875766|test MAE 3.4462032201597963\n",
      "Epochs340/500: \n",
      "Training cost 10.0347795536384|test cost 14.257215668814442\n",
      "Training MAE 3.1581673250614144|test MAE 3.4460018131351746\n",
      "Epochs341/500: \n",
      "Training cost 10.033513264786142|test cost 14.255465872584958\n",
      "Training MAE 3.1580305327721554|test MAE 3.4458009516573047\n",
      "Epochs342/500: \n",
      "Training cost 10.03225533017409|test cost 14.253730968408426\n",
      "Training MAE 3.157893675824478|test MAE 3.445600641048018\n",
      "Epochs343/500: \n",
      "Training cost 10.031005660713285|test cost 14.252010815102237\n",
      "Training MAE 3.157756759942612|test MAE 3.445400886481505\n",
      "Epochs344/500: \n",
      "Training cost 10.02976416873369|test cost 14.250305273394474\n",
      "Training MAE 3.157619790759826|test MAE 3.445201692986889\n",
      "Epochs345/500: \n",
      "Training cost 10.028530767956658|test cost 14.248614205889403\n",
      "Training MAE 3.1574827738197113|test MAE 3.4450030654507677\n",
      "Epochs346/500: \n",
      "Training cost 10.027305373467973|test cost 14.24693747703363\n",
      "Training MAE 3.1573457145774473|test MAE 3.444805008619706\n",
      "Epochs347/500: \n",
      "Training cost 10.02608790169144|test cost 14.245274953083026\n",
      "Training MAE 3.1572086184010435|test MAE 3.4446075271026992\n",
      "Epochs348/500: \n",
      "Training cost 10.024878270363056|test cost 14.243626502070331\n",
      "Training MAE 3.1570714905725725|test MAE 3.444410625373583\n",
      "Epochs349/500: \n",
      "Training cost 10.023676398505716|test cost 14.24199199377339\n",
      "Training MAE 3.15693433628938|test MAE 3.4442143077734135\n",
      "Epochs350/500: \n",
      "Training cost 10.02248220640444|test cost 14.240371299684123\n",
      "Training MAE 3.1567971606652736|test MAE 3.4440185785128077\n",
      "Epochs351/500: \n",
      "Training cost 10.021295615582142|test cost 14.238764292978052\n",
      "Training MAE 3.1566599687317067|test MAE 3.443823441674251\n",
      "Epochs352/500: \n",
      "Training cost 10.020116548775901|test cost 14.237170848484569\n",
      "Training MAE 3.1565227654389334|test MAE 3.443628901214349\n",
      "Epochs353/500: \n",
      "Training cost 10.0189449299137|test cost 14.235590842657686\n",
      "Training MAE 3.1563855556571516|test MAE 3.4434349609660675\n",
      "Epochs354/500: \n",
      "Training cost 10.017780684091713|test cost 14.234024153547528\n",
      "Training MAE 3.1562483441776363|test MAE 3.4432416246409234\n",
      "Epochs355/500: \n",
      "Training cost 10.016623737551999|test cost 14.2324706607723\n",
      "Training MAE 3.15611113571384|test MAE 3.4430488958311405\n",
      "Epochs356/500: \n",
      "Training cost 10.015474017660729|test cost 14.230930245490907\n",
      "Training MAE 3.1559739349025016|test MAE 3.44285677801177\n",
      "Epochs357/500: \n",
      "Training cost 10.0143314528868|test cost 14.229402790376097\n",
      "Training MAE 3.155836746304713|test MAE 3.4426652745427853\n",
      "Epochs358/500: \n",
      "Training cost 10.01319597278096|test cost 14.22788817958818\n",
      "Training MAE 3.1556995744069964|test MAE 3.4424743886711293\n",
      "Epochs359/500: \n",
      "Training cost 10.012067507955317|test cost 14.226386298749263\n",
      "Training MAE 3.1555624236223414|test MAE 3.4422841235327426\n",
      "Epochs360/500: \n",
      "Training cost 10.010945990063304|test cost 14.224897034918035\n",
      "Training MAE 3.155425298291253|test MAE 3.442094482154548\n",
      "Epochs361/500: \n",
      "Training cost 10.00983135178006|test cost 14.223420276565063\n",
      "Training MAE 3.1552882026827618|test MAE 3.4419054674564107\n",
      "Epochs362/500: \n",
      "Training cost 10.008723526783186|test cost 14.221955913548557\n",
      "Training MAE 3.1551511409954314|test MAE 3.441717082253064\n",
      "Epochs363/500: \n",
      "Training cost 10.007622449733953|test cost 14.2205038370907\n",
      "Training MAE 3.155014117358357|test MAE 3.4415293292559994\n",
      "Epochs364/500: \n",
      "Training cost 10.006528056258862|test cost 14.219063939754381\n",
      "Training MAE 3.1548771358321335|test MAE 3.441342211075336\n",
      "Epochs365/500: \n",
      "Training cost 10.005440282931582|test cost 14.217636115420461\n",
      "Training MAE 3.1547402004098277|test MAE 3.441155730221651\n",
      "Epochs366/500: \n",
      "Training cost 10.004359067255303|test cost 14.216220259265471\n",
      "Training MAE 3.1546033150179267|test MAE 3.4409698891077856\n",
      "Epochs367/500: \n",
      "Training cost 10.00328434764539|test cost 14.214816267739764\n",
      "Training MAE 3.154466483517269|test MAE 3.440784690050618\n",
      "Epochs368/500: \n",
      "Training cost 10.00221606341247|test cost 14.213424038546098\n",
      "Training MAE 3.1543297097039766|test MAE 3.44060013527281\n",
      "Epochs369/500: \n",
      "Training cost 10.001154154745805|test cost 14.212043470618696\n",
      "Training MAE 3.1541929973103664|test MAE 3.4404162269045293\n",
      "Epochs370/500: \n",
      "Training cost 10.000098562697026|test cost 14.210674464102661\n",
      "Training MAE 3.154056350005838|test MAE 3.440232966985134\n",
      "Epochs371/500: \n",
      "Training cost 9.999049229164232|test cost 14.20931692033387\n",
      "Training MAE 3.153919771397773|test MAE 3.44005035746484\n",
      "Epochs372/500: \n",
      "Training cost 9.998006096876365|test cost 14.207970741819208\n",
      "Training MAE 3.153783265032399|test MAE 3.4398684002063553\n",
      "Epochs373/500: \n",
      "Training cost 9.996969109377948|test cost 14.206635832217255\n",
      "Training MAE 3.1536468343956536|test MAE 3.439687096986488\n",
      "Epochs374/500: \n",
      "Training cost 9.995938211014115|test cost 14.205312096319318\n",
      "Training MAE 3.1535104829140375|test MAE 3.4395064494977334\n",
      "Epochs375/500: \n",
      "Training cost 9.994913346915943|test cost 14.203999440030879\n",
      "Training MAE 3.153374213955444|test MAE 3.439326459349829\n",
      "Epochs376/500: \n",
      "Training cost 9.99389446298611|test cost 14.202697770353355\n",
      "Training MAE 3.1532412226125937|test MAE 3.439147128071291\n",
      "Epochs377/500: \n",
      "Training cost 9.992881505884819|test cost 14.201406995366304\n",
      "Training MAE 3.153116134562963|test MAE 3.438968457110918\n",
      "Epochs378/500: \n",
      "Training cost 9.991874423016013|test cost 14.200127024209879\n",
      "Training MAE 3.1529943480623603|test MAE 3.438790447839276\n",
      "Epochs379/500: \n",
      "Training cost 9.990873162513893|test cost 14.198857767067741\n",
      "Training MAE 3.152872561104924|test MAE 3.4386131015501586\n",
      "Epochs380/500: \n",
      "Training cost 9.989877673229689|test cost 14.197599135150217\n",
      "Training MAE 3.1527507775066663|test MAE 3.4384364194620196\n",
      "Epochs381/500: \n",
      "Training cost 9.988887904718695|test cost 14.196351040677836\n",
      "Training MAE 3.152635143213967|test MAE 3.4382604027193944\n",
      "Epochs382/500: \n",
      "Training cost 9.9879038072276|test cost 14.195113396865201\n",
      "Training MAE 3.1525201168072794|test MAE 3.438085052394275\n",
      "Epochs383/500: \n",
      "Training cost 9.986925331682038|test cost 14.193886117905134\n",
      "Training MAE 3.1524050954404337|test MAE 3.437910369487493\n",
      "Epochs384/500: \n",
      "Training cost 9.98595242967441|test cost 14.19266911895316\n",
      "Training MAE 3.1522900826853775|test MAE 3.437736354930048\n",
      "Epochs385/500: \n",
      "Training cost 9.984985053451961|test cost 14.191462316112304\n",
      "Training MAE 3.1521750820574463|test MAE 3.4375630095844443\n",
      "Epochs386/500: \n",
      "Training cost 9.984023155905065|test cost 14.190265626418157\n",
      "Training MAE 3.152060097016132|test MAE 3.437390334245984\n",
      "Epochs387/500: \n",
      "Training cost 9.983066690555788|test cost 14.189078967824239\n",
      "Training MAE 3.151945130965849|test MAE 3.437218329644053\n",
      "Epochs388/500: \n",
      "Training cost 9.98211561154666|test cost 14.187902259187686\n",
      "Training MAE 3.151830187256688|test MAE 3.4370469964433754\n",
      "Epochs389/500: \n",
      "Training cost 9.981169873629668|test cost 14.186735420255149\n",
      "Training MAE 3.151724360883339|test MAE 3.4368763352452523\n",
      "Epochs390/500: \n",
      "Training cost 9.98022943215547|test cost 14.185578371649017\n",
      "Training MAE 3.1516270141535583|test MAE 3.436706346588785\n",
      "Epochs391/500: \n",
      "Training cost 9.979294243062858|test cost 14.184431034853887\n",
      "Training MAE 3.151534942573947|test MAE 3.4365370309520693\n",
      "Epochs392/500: \n",
      "Training cost 9.97836426286839|test cost 14.183293332203293\n",
      "Training MAE 3.151442805915829|test MAE 3.4363683887533774\n",
      "Epochs393/500: \n",
      "Training cost 9.977439448656243|test cost 14.1821651868667\n",
      "Training MAE 3.1513506077874895|test MAE 3.4362004203523178\n",
      "Epochs394/500: \n",
      "Training cost 9.976519758068301|test cost 14.181046522836734\n",
      "Training MAE 3.1512583517443815|test MAE 3.436033126050973\n",
      "Epochs395/500: \n",
      "Training cost 9.975605149294376|test cost 14.17993726491667\n",
      "Training MAE 3.1511660412898297|test MAE 3.435866506095027\n",
      "Epochs396/500: \n",
      "Training cost 9.9746955810627|test cost 14.178837338708162\n",
      "Training MAE 3.151073679875704|test MAE 3.4357005606748654\n",
      "Epochs397/500: \n",
      "Training cost 9.973791012630542|test cost 14.177746670599173\n",
      "Training MAE 3.1509812709031095|test MAE 3.435535289926663\n",
      "Epochs398/500: \n",
      "Training cost 9.972891403775057|test cost 14.176665187752183\n",
      "Training MAE 3.150888817723049|test MAE 3.4353706939334536\n",
      "Epochs399/500: \n",
      "Training cost 9.971996714784282|test cost 14.175592818092595\n",
      "Training MAE 3.1507963236370844|test MAE 3.435206772726178\n",
      "Epochs400/500: \n",
      "Training cost 9.971106906448346|test cost 14.174529490297342\n",
      "Training MAE 3.1507037918979863|test MAE 3.435043526284717\n",
      "Epochs401/500: \n",
      "Training cost 9.970221940050825|test cost 14.173475133783768\n",
      "Training MAE 3.1506112257103793|test MAE 3.434880954538913\n",
      "Epochs402/500: \n",
      "Training cost 9.969341777360283|test cost 14.172429678698641\n",
      "Training MAE 3.1505186282313717|test MAE 3.4347190573695667\n",
      "Epochs403/500: \n",
      "Training cost 9.968466380621981|test cost 14.171393055907448\n",
      "Training MAE 3.1504260025711863|test MAE 3.434557834609416\n",
      "Epochs404/500: \n",
      "Training cost 9.967595712549736|test cost 14.170365196983827\n",
      "Training MAE 3.1503333517937726|test MAE 3.434397286044112\n",
      "Epochs405/500: \n",
      "Training cost 9.966729736317964|test cost 14.169346034199238\n",
      "Training MAE 3.1502406789174198|test MAE 3.4342374114131666\n",
      "Epochs406/500: \n",
      "Training cost 9.965868415553853|test cost 14.168335500512818\n",
      "Training MAE 3.150147986915356|test MAE 3.4340782104108896\n",
      "Epochs407/500: \n",
      "Training cost 9.965011714329716|test cost 14.167333529561413\n",
      "Training MAE 3.1500552787163456|test MAE 3.433919682687304\n",
      "Epochs408/500: \n",
      "Training cost 9.964159597155474|test cost 14.166340055649806\n",
      "Training MAE 3.1499625572052667|test MAE 3.433761827849058\n",
      "Epochs409/500: \n",
      "Training cost 9.963312028971297|test cost 14.165355013741122\n",
      "Training MAE 3.1498698252236976|test MAE 3.4336046454603117\n",
      "Epochs410/500: \n",
      "Training cost 9.962468975140384|test cost 14.164378339447408\n",
      "Training MAE 3.14977708557048|test MAE 3.433448135043617\n",
      "Epochs411/500: \n",
      "Training cost 9.961630401441896|test cost 14.163409969020403\n",
      "Training MAE 3.149684341002289|test MAE 3.433292296080773\n",
      "Epochs412/500: \n",
      "Training cost 9.960796274064007|test cost 14.162449839342457\n",
      "Training MAE 3.1495915942341806|test MAE 3.433137128013675\n",
      "Epochs413/500: \n",
      "Training cost 9.9599665595971|test cost 14.161497887917616\n",
      "Training MAE 3.149498847940146|test MAE 3.4329826302451507\n",
      "Epochs414/500: \n",
      "Training cost 9.95914122502712|test cost 14.160554052862892\n",
      "Training MAE 3.1494061047536497|test MAE 3.432828802139778\n",
      "Epochs415/500: \n",
      "Training cost 9.958320237728996|test cost 14.159618272899666\n",
      "Training MAE 3.149313367268165|test MAE 3.432675643024689\n",
      "Epochs416/500: \n",
      "Training cost 9.95750356546027|test cost 14.158690487345275\n",
      "Training MAE 3.149220638037697|test MAE 3.4325231521903636\n",
      "Epochs417/500: \n",
      "Training cost 9.956691176354774|test cost 14.157770636104736\n",
      "Training MAE 3.1491279195773085|test MAE 3.432371328891409\n",
      "Epochs418/500: \n",
      "Training cost 9.955883038916483|test cost 14.156858659662593\n",
      "Training MAE 3.149035214363628|test MAE 3.432220172347326\n",
      "Epochs419/500: \n",
      "Training cost 9.95507912201346|test cost 14.155954499074987\n",
      "Training MAE 3.1489425248353604|test MAE 3.4320696817432643\n",
      "Epochs420/500: \n",
      "Training cost 9.954279394871923|test cost 14.15505809596177\n",
      "Training MAE 3.14884985339378|test MAE 3.43191985623076\n",
      "Epochs421/500: \n",
      "Training cost 9.953483827070446|test cost 14.154169392498861\n",
      "Training MAE 3.148757202403236|test MAE 3.431771062906175\n",
      "Epochs422/500: \n",
      "Training cost 9.952692388534224|test cost 14.15328833141065\n",
      "Training MAE 3.1486645741916233|test MAE 3.4316241033755306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs423/500: \n",
      "Training cost 9.95190504952951|test cost 14.152414855962585\n",
      "Training MAE 3.148571971050878|test MAE 3.4314778143558926\n",
      "Epochs424/500: \n",
      "Training cost 9.95112178065811|test cost 14.151548909953899\n",
      "Training MAE 3.148479395237443|test MAE 3.4313321946965307\n",
      "Epochs425/500: \n",
      "Training cost 9.950342552851996|test cost 14.150690437710452\n",
      "Training MAE 3.148386848972738|test MAE 3.4311872432192385\n",
      "Epochs426/500: \n",
      "Training cost 9.949567337368045|test cost 14.149839384077668\n",
      "Training MAE 3.148294334443622|test MAE 3.4310429587189644\n",
      "Epochs427/500: \n",
      "Training cost 9.948796105782856|test cost 14.148995694413655\n",
      "Training MAE 3.148201853802851|test MAE 3.4308993399644243\n",
      "Epochs428/500: \n",
      "Training cost 9.94802882998765|test cost 14.148159314582406\n",
      "Training MAE 3.148109409169524|test MAE 3.4307563856987167\n",
      "Epochs429/500: \n",
      "Training cost 9.94726548218332|test cost 14.147330190947141\n",
      "Training MAE 3.1480170026295293|test MAE 3.430614094639912\n",
      "Epochs430/500: \n",
      "Training cost 9.946506034875515|test cost 14.146508270363737\n",
      "Training MAE 3.1479246362359845|test MAE 3.430472465481648\n",
      "Epochs431/500: \n",
      "Training cost 9.945750460869862|test cost 14.14569350017431\n",
      "Training MAE 3.147832312009667|test MAE 3.4303314968936998\n",
      "Epochs432/500: \n",
      "Training cost 9.944998733267248|test cost 14.144885828200891\n",
      "Training MAE 3.1477400319394424|test MAE 3.4301911875225506\n",
      "Epochs433/500: \n",
      "Training cost 9.944250825459228|test cost 14.144085202739193\n",
      "Training MAE 3.147647797982685|test MAE 3.4300515359919537\n",
      "Epochs434/500: \n",
      "Training cost 9.943506711123462|test cost 14.143291572552506\n",
      "Training MAE 3.147555612065694|test MAE 3.429912540903475\n",
      "Epochs435/500: \n",
      "Training cost 9.942766364219306|test cost 14.142504886865725\n",
      "Training MAE 3.147463476084105|test MAE 3.4297742008370373\n",
      "Epochs436/500: \n",
      "Training cost 9.942029758983432|test cost 14.141725095359416\n",
      "Training MAE 3.147371391903296|test MAE 3.4296365143514502\n",
      "Epochs437/500: \n",
      "Training cost 9.941296869925557|test cost 14.14095214816403\n",
      "Training MAE 3.147279361358785|test MAE 3.4294994799849308\n",
      "Epochs438/500: \n",
      "Training cost 9.940567671824246|test cost 14.140185995854212\n",
      "Training MAE 3.1471873862566264|test MAE 3.4293630962556163\n",
      "Epochs439/500: \n",
      "Training cost 9.939842139722794|test cost 14.139426589443193\n",
      "Training MAE 3.1470954683738017|test MAE 3.429227361662072\n",
      "Epochs440/500: \n",
      "Training cost 9.939120248925187|test cost 14.138673880377267\n",
      "Training MAE 3.1470061777157534|test MAE 3.4291001355791457\n",
      "Epochs441/500: \n",
      "Training cost 9.938401974992123|test cost 14.137927820530422\n",
      "Training MAE 3.146921830141836|test MAE 3.4289743282047285\n",
      "Epochs442/500: \n",
      "Training cost 9.937687293737145|test cost 14.137188362198966\n",
      "Training MAE 3.1468375167136036|test MAE 3.4288492082731823\n",
      "Epochs443/500: \n",
      "Training cost 9.93697618122279|test cost 14.136455458096334\n",
      "Training MAE 3.146753239196255|test MAE 3.428724773527044\n",
      "Epochs444/500: \n",
      "Training cost 9.936268613756862|test cost 14.13572906134792\n",
      "Training MAE 3.1466689993276584|test MAE 3.4286010216990586\n",
      "Epochs445/500: \n",
      "Training cost 9.935564567888752|test cost 14.135009125486027\n",
      "Training MAE 3.14658479881871|test MAE 3.428477950512573\n",
      "Epochs446/500: \n",
      "Training cost 9.934864020405804|test cost 14.1342956044449\n",
      "Training MAE 3.14650063935369|test MAE 3.428355557681897\n",
      "Epochs447/500: \n",
      "Training cost 9.934166948329807|test cost 14.133588452555808\n",
      "Training MAE 3.1464165225906036|test MAE 3.428233840912666\n",
      "Epochs448/500: \n",
      "Training cost 9.93347332891348|test cost 14.132887624542274\n",
      "Training MAE 3.1463324501615277|test MAE 3.4281127979021995\n",
      "Epochs449/500: \n",
      "Training cost 9.93278313963708|test cost 14.13219307551531\n",
      "Training MAE 3.1462484236729518|test MAE 3.427992426339855\n",
      "Epochs450/500: \n",
      "Training cost 9.932096358205033|test cost 14.13150476096878\n",
      "Training MAE 3.1461644447061077|test MAE 3.4278727239073654\n",
      "Epochs451/500: \n",
      "Training cost 9.931412962542657|test cost 14.130822636774797\n",
      "Training MAE 3.146080514817305|test MAE 3.427753688279179\n",
      "Epochs452/500: \n",
      "Training cost 9.930732930792916|test cost 14.130146659179266\n",
      "Training MAE 3.1459966355382516|test MAE 3.427635317122789\n",
      "Epochs453/500: \n",
      "Training cost 9.930056241313261|test cost 14.12947678479742\n",
      "Training MAE 3.145912808376377|test MAE 3.427517608099059\n",
      "Epochs454/500: \n",
      "Training cost 9.929382872672509|test cost 14.12881297060947\n",
      "Training MAE 3.145829493927161|test MAE 3.4274005588625407\n",
      "Epochs455/500: \n",
      "Training cost 9.92871280364778|test cost 14.128155173956308\n",
      "Training MAE 3.145753171752443|test MAE 3.427284167061793\n",
      "Epochs456/500: \n",
      "Training cost 9.928046013221506|test cost 14.127503352535328\n",
      "Training MAE 3.1456768833895263|test MAE 3.4271684303396737\n",
      "Epochs457/500: \n",
      "Training cost 9.927382480578471|test cost 14.126857464396219\n",
      "Training MAE 3.145600630395133|test MAE 3.427053346333659\n",
      "Epochs458/500: \n",
      "Training cost 9.926722185102923|test cost 14.12621746793693\n",
      "Training MAE 3.1455244143015153|test MAE 3.4269389126761225\n",
      "Epochs459/500: \n",
      "Training cost 9.926065106375738|test cost 14.12558332189962\n",
      "Training MAE 3.1454482366167844|test MAE 3.4268251269946384\n",
      "Epochs460/500: \n",
      "Training cost 9.9254112241716|test cost 14.124954985366726\n",
      "Training MAE 3.1453720988252196|test MAE 3.426711986912255\n",
      "Epochs461/500: \n",
      "Training cost 9.9247605184563|test cost 14.124332417757044\n",
      "Training MAE 3.1452960023875915|test MAE 3.4265994900477788\n",
      "Epochs462/500: \n",
      "Training cost 9.92411296938401|test cost 14.123715578821926\n",
      "Training MAE 3.1452199487414694|test MAE 3.426487634016047\n",
      "Epochs463/500: \n",
      "Training cost 9.923468557294651|test cost 14.12310442864149\n",
      "Training MAE 3.145143939301519|test MAE 3.4263764164281985\n",
      "Epochs464/500: \n",
      "Training cost 9.92282726271131|test cost 14.122498927620923\n",
      "Training MAE 3.1450690861791233|test MAE 3.426265834891932\n",
      "Epochs465/500: \n",
      "Training cost 9.922189066337655|test cost 14.121899036486802\n",
      "Training MAE 3.145011094075206|test MAE 3.4261558870117654\n",
      "Epochs466/500: \n",
      "Training cost 9.921553949055465|test cost 14.121304716283529\n",
      "Training MAE 3.1449530976826354|test MAE 3.426046570389293\n",
      "Epochs467/500: \n",
      "Training cost 9.920921891922147|test cost 14.120715928369773\n",
      "Training MAE 3.144895098431643|test MAE 3.425937882623427\n",
      "Epochs468/500: \n",
      "Training cost 9.920292876168325|test cost 14.120132634414984\n",
      "Training MAE 3.144837097731856|test MAE 3.425829821310648\n",
      "Epochs469/500: \n",
      "Training cost 9.919666883195463|test cost 14.119554796395965\n",
      "Training MAE 3.144779096972564|test MAE 3.4257223840452395\n",
      "Epochs470/500: \n",
      "Training cost 9.919043894573536|test cost 14.118982376593468\n",
      "Training MAE 3.1447210975229716|test MAE 3.4256155684195195\n",
      "Epochs471/500: \n",
      "Training cost 9.918423892038735|test cost 14.118415337588925\n",
      "Training MAE 3.1446631007324584|test MAE 3.4255093720240755\n",
      "Epochs472/500: \n",
      "Training cost 9.917806857491213|test cost 14.117853642261087\n",
      "Training MAE 3.144605107930828|test MAE 3.425403792447986\n",
      "Epochs473/500: \n",
      "Training cost 9.917192772992875|test cost 14.117297253782867\n",
      "Training MAE 3.1445471204285633|test MAE 3.4252988272790414\n",
      "Epochs474/500: \n",
      "Training cost 9.9165816207652|test cost 14.116746135618127\n",
      "Training MAE 3.1444891395170647|test MAE 3.4251944741039604\n",
      "Epochs475/500: \n",
      "Training cost 9.915973383187115|test cost 14.116200251518547\n",
      "Training MAE 3.144431166468904|test MAE 3.425110263116755\n",
      "Epochs476/500: \n",
      "Training cost 9.915368042792883|test cost 14.115659565520545\n",
      "Training MAE 3.1443732025380524|test MAE 3.425052506271413\n",
      "Epochs477/500: \n",
      "Training cost 9.914765582270045|test cost 14.115124041942241\n",
      "Training MAE 3.144315248960129|test MAE 3.424995189597155\n",
      "Epochs478/500: \n",
      "Training cost 9.914165984457398|test cost 14.114593645380454\n",
      "Training MAE 3.144257306952627|test MAE 3.424938311586698\n",
      "Epochs479/500: \n",
      "Training cost 9.913569232342997|test cost 14.114068340707764\n",
      "Training MAE 3.1441993777151462|test MAE 3.4248818707252457\n",
      "Epochs480/500: \n",
      "Training cost 9.912975309062197|test cost 14.113548093069598\n",
      "Training MAE 3.1441414624296273|test MAE 3.4248258654907566\n",
      "Epochs481/500: \n",
      "Training cost 9.912384197895735|test cost 14.113032867881373\n",
      "Training MAE 3.1440835622605694|test MAE 3.424770294354203\n",
      "Epochs482/500: \n",
      "Training cost 9.911795882267832|test cost 14.112522630825664\n",
      "Training MAE 3.1440256783552565|test MAE 3.424715155779829\n",
      "Epochs483/500: \n",
      "Training cost 9.911210345744328|test cost 14.112017347849436\n",
      "Training MAE 3.143967811843976|test MAE 3.4246604482254015\n",
      "Epochs484/500: \n",
      "Training cost 9.910627572030876|test cost 14.111516985161305\n",
      "Training MAE 3.1439099638402364|test MAE 3.4246061701424626\n",
      "Epochs485/500: \n",
      "Training cost 9.910047544971125|test cost 14.111021509228815\n",
      "Training MAE 3.143852135440982|test MAE 3.4245530703415907\n",
      "Epochs486/500: \n",
      "Training cost 9.909470248544963|test cost 14.11053088677581\n",
      "Training MAE 3.143794327726804|test MAE 3.424527773825641\n",
      "Epochs487/500: \n",
      "Training cost 9.908895666866778|test cost 14.110045084779786\n",
      "Training MAE 3.143736541762147|test MAE 3.4245028118651866\n",
      "Epochs488/500: \n",
      "Training cost 9.908323784183759|test cost 14.109564070469327\n",
      "Training MAE 3.14367877859552|test MAE 3.4244781832811944\n",
      "Epochs489/500: \n",
      "Training cost 9.907754584874203|test cost 14.109087811321524\n",
      "Training MAE 3.143621039259695|test MAE 3.4244538868871994\n",
      "Epochs490/500: \n",
      "Training cost 9.907188053445882|test cost 14.108616275059505\n",
      "Training MAE 3.1435633247719115|test MAE 3.424429921489536\n",
      "Epochs491/500: \n",
      "Training cost 9.906624174534409|test cost 14.108149429649911\n",
      "Training MAE 3.1435056361340754|test MAE 3.424406285887575\n",
      "Epochs492/500: \n",
      "Training cost 9.90606293290165|test cost 14.107687243300509\n",
      "Training MAE 3.143447974332951|test MAE 3.4243829788739624\n",
      "Epochs493/500: \n",
      "Training cost 9.905504313434145|test cost 14.10722968445772\n",
      "Training MAE 3.143390340340358|test MAE 3.4243599992348264\n",
      "Epochs494/500: \n",
      "Training cost 9.904948301141578|test cost 14.10677672180431\n",
      "Training MAE 3.1433327351133635|test MAE 3.424337345750023\n",
      "Epochs495/500: \n",
      "Training cost 9.90439488115526|test cost 14.106328324256982\n",
      "Training MAE 3.1432751595944666|test MAE 3.4243150171933396\n",
      "Epochs496/500: \n",
      "Training cost 9.903844038726625|test cost 14.105884460964143\n",
      "Training MAE 3.1432176147117894|test MAE 3.4242930123327193\n",
      "Epochs497/500: \n",
      "Training cost 9.903295759225768|test cost 14.105445101303557\n",
      "Training MAE 3.1431601013792583|test MAE 3.4242713299304657\n",
      "Epochs498/500: \n",
      "Training cost 9.90275002814001|test cost 14.105010214880135\n",
      "Training MAE 3.143102620496786|test MAE 3.424249968743459\n",
      "Epochs499/500: \n",
      "Training cost 9.90220683107247|test cost 14.10457977152372\n",
      "Training MAE 3.1430451729504516|test MAE 3.4242289275233504\n",
      "Epochs500/500: \n",
      "Training cost 9.901666153740667|test cost 14.104153741286893\n",
      "Training MAE 3.1429877596126783|test MAE 3.424208205016772\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feeding prepared dataset into our learning regression model.\n",
    "# notice from the plot our model training cost and test cost is decreasing after more iterations of training.\n",
    "linear_regression_model(X_train, y_train, X_test, y_test, 0.4, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the accuracy of our model with the model from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = linear_model.LinearRegression()\n",
    "# the model in sklearn requires(mxn X matrix where m is # data samples, n is number of features).\n",
    "# also y vector of dimensions mx1\n",
    "model = linear_regression.fit(X_train.T, y_train.T) \n",
    "predictions = linear_regression.predict(X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 1)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.455034932248353"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mean absolute error of the test set with the sklearn model.\n",
    "MAE_test_with_sklearn = (1 / y_test.shape[1]) * np.sum(np.abs(predictions - y_test.T))\n",
    "MAE_test_with_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We conclude that the MAE of our manually written multivariate_linear_regression model is less than that of the sklearn model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
